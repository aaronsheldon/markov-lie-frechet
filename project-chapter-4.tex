\chapter{Maximum Likelihood Estimation from First Hitting Times}
\section{Distribution of First Hitting Times}
Contemporary methods for fitting time homogeneous Markov processes on a finite 
state space require directly parameterizing the transition probability matrix $\mathbb{P}\left[X_n = j \left\|X_0 = i \right.\right] = \hat{e}_i P^n \hat{e}_j$,
as they depend on realizing the process through discrete time steps $n$. While this 
formulation has many powerful applications, there are analyses where the parameterization of 
the generator of the time homogeneous Markov process, $\mathbb{P}\left[X_t = j \left\|X_0 = i \right.\right] = \hat{e}_i \exp\left({tG}\right) \hat{e}_j$, 
is of greater meaning, or importance. In particular when the observed process is, at least,
in principle continuous, or when the desired parameterization is in units of rates per time
parameterization of the generator is the more natural choice.

The natural experimental design for continuous time homogeneous Markov process on a finite
state space is the observation of a stopped process, such as the first hitting time to a
state statistic, or the first exit time from a state statistic. Surprisingly it is possible
to explicitly formulate the distribution of these two statistics in terms of the generator
of the process.

To start, recall the definition of the projection operator on a finite dimensional vector
space $P_i = \hat{e}_i \otimes \hat{e}_i$; which projects each vector in the space onto a
fixed unit vector $\hat{e}_i$. Projection operators hold a special purpose in analyzing
continuous time homogeneous Markov processes on a finite state spaces. The projection
operator $P_k$ when right multiplied to the generator $G = \sum_{ij}x_{ij}C_{ij}$, yields a
new process $GP_k$ where all states are absorbed by state $k$. Likewise when $P_k$ is left
multiplied by the generator $G$ the resulting process $P_kG$ has all states, but $k$, acting as
absorbing states.


% Fill in the blanks

We can reformulate the standard textbook results, for example in Buchholz et. al \cite{buchholz_input_2014},
of first exit and first hitting time statistics in the context of the stochastic contraction
Lie algebra $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$. As is standard we start with an the 
experiment designed to observe the first exit time $T_{i \rightarrow j}$ from $\hat{e_i}$ to
every other state $\hat{e}_j$, where $i \ne j$. Assuming the process is generated by $G = \sum_{ij}x_{ij}C_{ij}$, 
and keeping $i \ne j$ fixed, the density of the conditional distribution of $T_{i \rightarrow j}$
is
\begin{IEEEeqnarray*}{rCl}
	p\left(X_t=j \left\| X_0=i \right.\right)
		& = & \frac{d}{dt} \mathbb{P}\left[X_T=j, T\le t \left\| X_0=i \right.\right]\\
		& = & \frac{d}{dt} \hat{e_i} \exp\left(tP_iG\right) \hat{e}_j\\
		& = & \hat{e_i} P_iG \exp\left(tP_iG\right) \hat{e}_j\\
		& = & \hat{e_i} \left(\sum_{l \ne i} x_{il} C_{il}\right) \exp\left(t\sum_{l \ne i} x_{il} C_{il}\right) \hat{e}_j\\
		& = & \left(\sum_{l \ne i} x_{il}\left(\hat{e}_l  - \hat{e}_i\right) \right) \left(- e^{-tx_{ij}}\right) \hat{e}_i\\
		& = & x_{ij} e^{-tx_{ij}}
\end{IEEEeqnarray*}
Intuitively if we design our experiment to observer the durations $t_n = T_{i \rightarrow j}$
between $N_{ij}$ replicated transitions $i \rightarrow j$, the maximum likelihood estimate of
each rate $x_{ij}$ is then the simple average
\begin{IEEEeqnarray*}{rCl}
	\tilde{x}_{ij}
		& = & \frac{N_{ij}}{\sum_{n=1}^{N_{ij}} t_n}
\end{IEEEeqnarray*}
However for experiments that involve opportunistic sampling, surveys, or population
monitoring it is generally not possible to observe every distinct transition. Typically the
initial state of the transition is known or can be inferred, but only a subset of exit
states are observed. In this situation the projection operator $P_i$ onto a single
dimensional subspace is replaced with a projection $I - P_A = P_{i_1} + P_{i_2} + \cdots$ onto a 
multidimensional subspace; where $P_A$ is the projection onto the observed absorbing states
in set $A$.



%With total knowledge of all first hits p_ij=N_ij/T_ij
%Prove its a stopped process where we take the product with the projection onto 
%all the other transitative states. Essentially zero out the rows of the states
%we observe first hitting on, turn them into absorbing states
% Introduce simple linear parameterization of the vector space of the algebra
\section{The Likelihood and Its Maximization}
%Long formula basically
\section{Newton-Raphson Maximization}
\section{Figures and Illustrations}