\chapter{Conclusion}
\section{Summary of Results}
In chapter two we reversed the normal development of stochastic matrices; which
usually starts with characterizing matrices as having non-negative entries with
fixed row sums in a standard orthonormal basis $\hat{e}_i$. The line of typical
development then notices that the vector $\vec{\mathbbm{1}} = \sum_{i=1}^n \hat{e}_i$
is an Eigenvector. Instead we began by characterizing all invertible matrices $A$ 
such that $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ with respect to a fixed unit 
vector $\hat{\mathbbm{1}}$. We showed that there is always a basis $\hat{e}_i$ 
such that $\vec{\mathbbm{1}} = \sqrt{n} \hat{\mathbbm{1}}$ can be interpreted as 
the row sum vector, and found that this allowed us to characterize both the Lie 
group in which the matrices $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ reside, 
and the Lie algebra tangent to the Lie group. We denoted these the $St(\hat{\mathbbm{1}})$ 
stochastic Lie group with respect to $\hat{\mathbbm{1}}$ and $\mathfrak{st}(\hat{\mathbbm{1}})$ 
the stochastic Lie group with respect to $\hat{\mathbbm{1}}$. We further 
characterized the doubly stochastic Lie group and algebra with respect to $\hat{\mathbbm{1}}$, 
denoted $St(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$ and $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$,
of invertible matrices of fixed row and column sums with respect to $\hat{\mathbbm{1}}$,
by generalizing the stochastic Lie group and algebra to the dual stochastic Lie
group and algebra, $St^T(\hat{\mathbbm{1}})$ and $\mathfrak{st}^T(\hat{\mathbbm{1}})$, 
of invertible matrices such that $A^T \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
\section{Discussion}
Application of Lie Theory to the embedding problem for first hitting times...
Differentiate between problem of choosing a branch of the matrix logarithm
and multiple Markov models having the same first hitting time distribution.
Once a principle branch of the logarithm is fixed stochastic Lie algebra can 
give meaning to the idea of a simplest model, the one expressed in the fewest 
canonical generators.

Pad\'{e} approximation needs optimization. The Kronecker vectorization means 
only low to moderate dimensional models can be handled, due to the quadratic
scaling.