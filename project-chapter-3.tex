\chapter{Pad\'{e} Approximation of the Fr\'{e}chet Derivatives of the Exponential Map}
\section{The Gradient}
Moler and Van Loan seminally reviewed algorithms for calculating the matrix 
exponential in 1978, and revisited that review in 2003\cite{moler_nineteen_1978,moler_nineteen_2003}. 
Building on the discussions of Moler and Van Loan, Higham established the 
standard implementation of the matrix exponential based on scaling and scaring 
and Pad\'{e} approximation\cite{higham_scaling_2005,higham_functions_2008}.
The Higham implementation was further optimized for $64$ bit architectures by 
Al-Mohy\cite{al-mohy_new_2009}. In the same work Al-Mohy developed an algorithm 
to approximate the derivative of the matrix exponential, formulated by taking 
the derivative of the Pad\'{e} approximation of the matrix exponential, and then 
working out a recursive calculation for the derivatives of matrix powers\cite{al-mohy_computing_2009}.

While the derivative of the Pad\'{e} approximation of an analytic function will 
converge to the derivative of the analytic function, it is not true that the
derivative of the Pad\'{e} approximation of an analytic function is the Pad\'{e} 
approximation of the derivative of an analytic function. In the sense that 
Pad\'{e} approximations of analytic functions are an optimal series of algebraic 
approximations the 2009 method proposed by Al-Mohy is not optimal.

In this chapter we will develop an approximation for the first, and second order
Fr\'{e}chet derivatives of the matrix exponential, by decomposing the 
derivatives into components that hold for the commutative condition, and 
components containing the perturbation due to non-commutativity. We will then 
derive the Pad\'{e} approximation for the non-commutative perturbation. We begin 
by listing the eight forms of the Fr\'{e}chet derivative of exponential map, in 
the direction $\frac{\partial X}{\partial x}$ at the point $X$ in the Lie 
algebra.
\footnote{We have abused and confounded the notations for directional 
derivatives and partial derivatives here by assuming that $X$ is parameterized 
by $x$ so that $\frac{\partial e^X}{\partial x}$ is the derivative in the
direction of change of $x$.}
\footnote{With respect to the adjoint operator, we are using the currying 
partial application notation of $\left[L f\left(\cdotp\right)\right]\left(y\right)$
to indicate the application of the operator $L$ to $f\left(x\right)$ followed by
evaluation of the result at $y$.}

{\setlength{\IEEEnormaljot}{18pt}
\begin{IEEEeqnarray*}{rClls}
	\frac{\partial e^X}{\partial x}
		& = & e^X \left[\int_0^1 e^{- s\operatorname{ad}_{X} \cdotp} ds \right] \left(\frac{\partial X}{\partial x}\right) & & \\
		& = & e^X \left[\frac{1 - e^{-\operatorname{ad}_X \cdotp}}{\operatorname{ad}_X \cdotp}\right]\left(\frac{\partial X}{\partial x}\right) & \smash{\left. \IEEEstrut[4\jot] \right\rbrace} & \text{left recursive} \\
		& = & e^X \left[\sum_{n=0}^{\infty} \frac{\left(-1\right)^n}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\frac{\partial X}{\partial x}\right) & & \\
		& = & \left[ \frac{\operatorname{ad}_{e^X} \cdotp}{\operatorname{ad}_X \cdotp} \right]\left(\frac{\partial X}{\partial x}\right) & & \text{adjoint ratio} \\
		& = & e^{\frac{1}{2}X} \left[ \frac{e^{\frac{1}{2}\operatorname{ad}_X \cdotp } - e^{-\frac{1}{2}\operatorname{ad}_X \cdotp}}{\operatorname{ad}_X \cdotp} \right]\left(\frac{\partial X}{\partial x}\right) e^{\frac{1}{2}X} & & \text{hyperbolic} \\
		& = & \left[ \int_0^1 e^{s \operatorname{ad}_{X} \cdotp} ds \right]\left(\frac{\partial X}{\partial x}\right) e^X & &\\
		& = & \left[ \frac{e^{\operatorname{ad}_X \cdotp} - 1}{\operatorname{ad}_X \cdotp} \right] \left(\frac{\partial X}{\partial x}\right) e^X & \smash{\left. \IEEEstrut[4\jot] \right\rbrace} & \text{right recursive}\\
		& = & \left[\sum_{n=0}^{\infty} \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\frac{\partial X}{\partial x} \right) e^X & &
\end{IEEEeqnarray*}}

The last equality demonstrates the non-commutative perturbation term most 
clearly; where the first multiplicative factor in the derivative accounts for 
the lack of commutativity between $X$ and $\frac{\partial X}{\partial x}$, and 
the last term resembles the derivative in the commutative case. This can be seen 
clearly when considering the condition $\left[X,\frac{\partial X}{\partial x}\right]=0$ 
in which case $\frac{\partial e^X}{\partial x} = \frac{\partial X}{\partial x} e^X$. 

Even though the multiplicative factorization provides a transparent 
representation of the computational terms it is still far from optimal; because,
when compared to matrix addition, matrix multiplication is both computationally 
more expensive, and less numerically stable. The numerical stability, and 
efficiency can be improved by decomposing the first multiplicative factor into a 
linear sum of the non-commutative perturbation term, which will reduce to $0$ 
when $\left[X,\frac{\partial X}{\partial x}\right]=0$, and an invariant term 
that contains the commutative relationship for all $X$.

\begin{IEEEeqnarray*}{rCl}
	\frac{\partial e^X}{\partial x}
		& = & \left[\frac{e^{\operatorname{ad}_X \cdotp} - 1 - \operatorname{ad}_X \cdotp }{\operatorname{ad}_X^2 \cdotp} \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) e^X + \frac{\partial X}{\partial x} e^X\\
		& = & \underbrace{\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right)}_{\text{non-commutative anomaly}} e^X + \underbrace{\frac{\partial X}{\partial x}}_{\text{invariant}} e^X
\end{IEEEeqnarray*}

Formally the infinite series in the non-commutative perturbation is related to 
the lower incomplete gamma function $\gamma\left(n,x\right)$. This can be seen 
by considering the general case when the offset of $2$ in the factorial is 
allowed to be any natural number $n$, and then restating the sum in terms of a 
truncated exponential series.

\begin{IEEEeqnarray*}{rCl}
	\sum_{m=0}^{\infty} \frac{x^m}{\left(m+n\right)!}
		& = & \frac{1}{x^n} \sum_{m=n}^{\infty} \frac{x^m}{m!}\\
		& = & \frac{1}{x^n} \left(e^x - \sum_{m=0}^{n-1}\frac{x^m}{m!} \right)\\
		& = & \frac{1}{x^n} \left(e^x - e^x \frac{\Gamma\left(n,x\right)}{\Gamma\left(n\right)}\right)\\
		& = & \frac{e^x}{\left(n-1\right)! x^n} \left(\int_0^{\infty} t^{n-1}e^{-t}dt - \int_x t^{n-1} e^{-t}dt \right)\\
		& = & \frac{e^x}{\left(n-1\right)! x^n} \int_0^x t^{n-1}e^{-t}dt\\
		& = & \frac{e^x}{\left(n-1\right)! x^n} \gamma\left(n,x\right)
\end{IEEEeqnarray*}

The non-commutative perturbation series is linear in $\frac{\partial X}{\partial x}$ 
and a Taylor series in the powers of $\operatorname{ad}_X \cdotp$, thus any 
computation of an approximation will be in the powers of $\operatorname{ad}_X \cdotp$. 
As was discussed in the background material, naive computation of the Taylor 
series itself results in an approximation that will converge slowly, requiring a
larger number of powers to be computed before the threshold of floating point 
error is reached. Pad\'{e} approximation by rational functions remedy this 
problem, by offering convergence to the threshold of floating point error in 
smaller powers, and fewer computational steps.

However the question remains, given that $\frac{e^{x} -1 - x}{x^2}$ is a 
rational perturbation of $e^x$, why not simply reuse the polynomials of the 
Pad\'{e} approximation of the exponential function to compute new polynomials 
for a rational approximation of the non-commutative perturbation Taylor series. 
This method has two shortcomings: first, the approximation found in this manner 
is not itself a Pad\'{e} approximation of the anomaly Taylor series, and so is 
not bound by the same theoretical asymptotic results as Pad\'{e} approximations;
second, computation by $\frac{e^{x} -1 - x}{x^2}$ suffers from the same floating 
point errors near $0$ as naive computation of $e^x - 1$ by first computing $e^x$ 
and then subtracting $1$.

While it is clear that $\frac{e^x}{x^2}\gamma\left(2,x\right) : x \mapsto \frac{e^{x} -1 - x}{x^2}$ 
is analytic for $x \in \mathbb{R}$ or $x \in \mathbb{C}$, and thus can be 
approximated by a Pad\'{e} series with coefficients in $\mathbb{C}$; that the
rational approximation with the same coefficients can be extended to $\operatorname{ad}_X \cdotp$ 
requires more careful consideration.

Blah, blah, blah the next paragraphs are non-sense and needing replacing. Instead 
show that the adjoint belongs to an algebra, so that solutions $Y$ to rational 
equations $P(X)=Q(X)Y$ can be found, when they exist, should make it clear $[P(X),Q(X)]=0$,
as part of justifying rational approximation vis-a-vi can be computed using 
standard linear algebra. After that return to developing how to carry out of the 
computation using Kronecker representation of adjoint. Need to point out that
the adjoint in a linear operator itself so has a representation as matrix.

The operator $\operatorname{ad}_X \cdotp$ has tensorial relationships to the 
underlying vector space on which $X$ is a linear operator. Specifically $\operatorname{ad}_X \cdotp$
is a bounded, and thus continuous, linear operator, such that if the underlying 
vector space is $n$ dimensional then the vector space of linear operators is 
$n^2$ dimensional, and $\operatorname{ad}_X \cdotp$ by tensor extension can be 
represented as an $n^2 \times n^2$ matrix. 

Computational the powers of $\operatorname{ad}_X \cdotp$ can be calculated 
through the Kronecker representation, which requires representing the matrices 
as vectors. The vector representation of a matrix is achieved by the matrix 
reshaping  operator $\operatorname{vec}\left(Y\right) = \vec{y}$, which forms a 
vector $\vec{y}$ by concatenation of the columns of $Y$, called vectorization. 
We denote the inverse operator to vectorization $\operatorname{mat}\left(\vec{y}\right) = \operatorname{vec}^{-1}\left(\vec{y}\right) = Y$,
which reshapes a vector, $n^2$, into an $n \times n$ matrix.

After juggling the indexes of $\operatorname{vec}\left(\frac{\partial X}{\partial x}\right)$, 
the Kronecker representation follows as

\begin{IEEEeqnarray*}{rCl}
	\operatorname{ad}_X \frac{\partial X}{\partial x} 
		& = & \operatorname{mat}\left( \left(I \otimes X - X^T \otimes I \right) \operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right)
\end{IEEEeqnarray*}

Proceeding by induction we find that 

\begin{IEEEeqnarray*}{rCl}
	\operatorname{ad}_X^n \frac{\partial X}{\partial x} 
		& = & \operatorname{mat}\left(\left(I \otimes X - X^T \otimes I \right)^n\operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right)
\end{IEEEeqnarray*}

It follows that $\frac{\partial e^X}{\partial x}$ can be computed by

\begin{IEEEeqnarray*}{rCl}
	\frac{\partial e^X}{\partial x}
		& = & \operatorname{mat}\left(\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \left(I \otimes X - X^T \otimes I \right)^n \operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right) e^X + \frac{\partial X}{\partial x} e^X
\end{IEEEeqnarray*}

% break the algorithm into two parts, Pade and perturbation
% need table of [16/16] coefficients.

% Consider parameterization sub-manifold in Lie algebra, algebraic closure
% guareentees finite computations will be in Lie group. Furthermore because
% polytope is in closure, limits will be proper row sum, but might lose invertibility

\section{The Hessian}

Need preamble on combinatorics of powers of adjoint.

\begin{lemma}
	For any matrix $A$, differentiable matrix function $X$ parameterized by $x \in \mathbb{R}$, and integer $n \ge 0$
	\begin{IEEEeqnarray*}{rCl}
		\left[\frac{\partial}{\partial x}\operatorname{ad}_X^n\right]\left( A\right)
			& = & \sum_{k=1}^n \left(\operatorname{ad}_X^{k-1} A \right)\left(\operatorname{ad}_{\frac{\partial X}{\partial x}} A\right)  \left(\operatorname{ad}_X^{n-k} A \right)
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	Proceed by induction on $n$.\hfill\IEEEQEDhere
\end{IEEEproof}

\begin{lemma}
	For any matrices $X,A,B$, and integer $n \ge 0$
	\begin{IEEEeqnarray*}{rCl}
		\operatorname{ad}_X^n AB
			& = & \sum_{k=0}^n \binom{n}{k} \left(\operatorname{ad}_X^k A \right)\left(\operatorname{ad}_X^{n-k} B \right)
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	Proceed by induction on $n$.\hfill\IEEEQEDhere
\end{IEEEproof}

\begin{lemma}
	For any matrices $X,A,B$, and integer $n \ge 0$
	\begin{IEEEeqnarray*}{rCl}
		\operatorname{ad}_X^n \left[A,B\right]
			& = & \sum_{k=0}^n \binom{n}{k} \left[\operatorname{ad}_X^k A , \operatorname{ad}_X^{n-k} B \right]
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	Take the antisymmetric difference of previous lemma.\hfill\IEEEQEDhere
\end{IEEEproof}

\begin{lemma}
	For any $n,m \ge 0$
	\begin{IEEEeqnarray*}{rCl}
		\sum_{k=m}^{n+m} \binom{k}{m}
			& = & \binom{n+m+1}{n}
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	Proceed by induction on $n$.\hfill\IEEEQEDhere
\end{IEEEproof}

\begin{corollary}
	For any differentiable matrix function $X$ parameterized by $x,y \in \mathbb{R}$
	\begin{IEEEeqnarray*}{rCl}
		\IEEEeqnarraymulticol{3}{l}
		{
			\left[\frac{\partial}{\partial x} \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right]\left(\frac{\partial X}{\partial y}\right)
			+ \left[\frac{\partial}{\partial y} \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right]\left(\frac{\partial Y}{\partial x}\right)
		}\\\quad
			& = & \sum_{n \ge m \ge 0} \frac{1}{\left(n+2\right)!} \left(\binom{n+1}{m+1} - \binom{n+1}{m} \right) \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n-m} \frac{\partial X}{\partial y} \right]
	\end{IEEEeqnarray*}
\end{corollary}

\begin{IEEEproof}
	Apply the previous lemmas in the order there were stated to the symmetric sum 
	of the two terms.
	\begin{IEEEeqnarray*}{rCl}
		\IEEEeqnarraymulticol{3}{l}
		{
			\left[\frac{\partial}{\partial x} \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right]\left(\frac{\partial X}{\partial y}\right)
			+ \left[\frac{\partial}{\partial y} \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right]\left(\frac{\partial Y}{\partial x}\right)
		}\\\quad
			& = & \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \operatorname{ad}_X^{k-1} \operatorname{ad}_{\frac{\partial X}{\partial x}} \operatorname{ad}_X^{n-k} \frac{\partial X}{\partial y}\\
			&   & +\: \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \operatorname{ad}_X^{k-1} \operatorname{ad}_{\frac{\partial X}{\partial y}} \operatorname{ad}_X^{n-k} \frac{\partial X}{\partial x}\\
			& = & \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \operatorname{ad}_X^{k-1} \left[ \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n-k} \frac{\partial X}{\partial y} \right]\\
			&   & +\: \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \operatorname{ad}_X^{k-1} \left[ \frac{\partial X}{\partial y} ,\operatorname{ad}_X^{n-k} \frac{\partial X}{\partial x} \right]\\
			& = & \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \sum_{m=0}^{k-1} \binom{k-1}{m} \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n-m-1} \frac{\partial X}{\partial y} \right]\\
			&   & +\: \sum_{n=1}^\infty \frac{1}{\left(n+1\right)!} \sum_{k=1}^n \sum_{m=0}^{k-1} \binom{k-1}{m} \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial y} ,\operatorname{ad}_X^{n-m-1} \frac{\partial X}{\partial x} \right]\\
			& = & \sum_{n=0}^\infty \frac{1}{\left(n+2\right)!} \sum_{k=0}^n \sum_{m=0}^{k} \binom{k}{m} \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n-m} \frac{\partial X}{\partial y} \right]\\
			&   & +\: \sum_{n=0}^\infty \frac{1}{\left(n+2\right)!} \sum_{k=0}^n \sum_{m=0}^{k} \binom{k}{m} \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial y} ,\operatorname{ad}_X^{n-m} \frac{\partial X}{\partial x} \right]\\
			& = & \sum_{n,m \ge 0}^\infty \frac{1}{\left(n+m+2\right)!} \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n} \frac{\partial X}{\partial y} \right] \sum_{k=m}^{n+m} \binom{k}{m}\\
			&   & +\: \sum_{n,m \ge 0}^\infty \frac{1}{\left(n+m+2\right)!} \left[\operatorname{ad}_X^{n} \frac{\partial X}{\partial y} ,\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} \right] \sum_{k=n}^{n+m} \binom{k}{n}\\
			& = & \sum_{n,m \ge 0}^\infty \frac{1}{\left(n+m+2\right)!} \left(\binom{n+m+1}{n} - \binom{n+m+1}{m} \right) \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n} \frac{\partial X}{\partial y} \right]\\
			& = & \sum_{n \ge m \ge 0} \frac{1}{\left(n+2\right)!} \left(\binom{n+1}{m+1} - \binom{n+1}{m} \right) \left[\operatorname{ad}_X^{m} \frac{\partial X}{\partial x} ,\operatorname{ad}_X^{n-m} \frac{\partial X}{\partial y} \right]\\
			& = & \sum_{n=0}^\infty \frac{1}{\left(n+2\right)!} F_n
	\end{IEEEeqnarray*}
	Where we have defined $F_n$ recursively as:
	\begin{IEEEeqnarray*}{rCl}
		F_0 & = & 0\\
		F_{n+1} & = &  \left[\frac{\partial X}{\partial x},\operatorname{ad}_X^{n+1} \frac{\partial X}{\partial y}\right] + \operatorname{ad}_X F_n - \left[\operatorname{ad}_X^{n+1} \frac{\partial X}{\partial x},\frac{\partial X}{\partial y}\right]
	\end{IEEEeqnarray*}
	This recursive calculation is illustrate in figure \ref{fig:pascaldivergence},
	and the proof is found by carrying out induction on $n$.\hfill\IEEEQEDhere
\end{IEEEproof}

\begin{figure}
	\centering
	\begin{tikzpicture}
		\node[text=gray] at (   0,  0) {$ 0$};
		
		\node[text=gray] at (-1/2, -1) {$ 1$};
		\node[text=gray] at ( 1/2, -1) {$-1$};
		
		\node[text=gray] at (  -1, -2) {$ 1$};
		\node[font=\bf ] at (   0, -2) {$ 0$};
		\node[text=gray] at (   1, -2) {$-1$};
		
		\node[text=gray] at (-3/2, -3) {$ 1$};
		\node[font=\bf ] at (-1/2, -3) {$ 1$};
		\node[font=\bf ] at ( 1/2, -3) {$-1$};
		\node[text=gray] at ( 3/2, -3) {$-1$};
		
		\node[text=gray] at (  -2, -4) {$ 1$};
		\node[font=\bf ] at (  -1, -4) {$ 2$};
		\node[font=\bf ] at (   0, -4) {$ 0$};
		\node[font=\bf ] at (   1, -4) {$-2$};
		\node[text=gray] at (   2, -4) {$-1$};
		
		\node[text=gray] at (-5/2, -5) {$ 1$};
		\node[font=\bf ] at (-3/2, -5) {$ 3$};
		\node[font=\bf ] at (-1/2, -5) {$ 2$};
		\node[font=\bf ] at ( 1/2, -5) {$-2$};
		\node[font=\bf ] at ( 3/2, -5) {$-3$};
		\node[text=gray] at ( 5/2, -5) {$-1$};
		
		\node[text=gray] at (  -3, -6) {$ 1$};
		\node[font=\bf ] at (  -2, -6) {$ 4$};
		\node[font=\bf ] at (  -1, -6) {$ 5$};
		\node[font=\bf ] at (   0, -6) {$ 0$};
		\node[font=\bf ] at (   1, -6) {$-5$};
		\node[font=\bf ] at (   2, -6) {$-4$};
		\node[text=gray] at (   3, -6) {$-1$};
		
		\node[text=gray] at (-7/2, -7) {$ 1$};
		\node[font=\bf ] at (-5/2, -7) {$ 5$};
		\node[font=\bf ] at (-3/2, -7) {$ 9$};
		\node[font=\bf ] at (-1/2, -7) {$ 5$};
		\node[font=\bf ] at ( 1/2, -7) {$-5$};
		\node[font=\bf ] at ( 3/2, -7) {$-9$};
		\node[font=\bf ] at ( 5/2, -7) {$-5$};
		\node[text=gray] at ( 7/2, -7) {$-1$};
		
		\node[text=gray] at (  -4, -8) {$\left[\frac{\partial X}{\partial x},\operatorname{ad}_X^{n+1} \frac{\partial X}{\partial y}\right]$};
		\node[text=gray] at (   4, -8) {$-\left[\operatorname{ad}_X^{n+1} \frac{\partial X}{\partial x},\frac{\partial X}{\partial y}\right]$};
	\end{tikzpicture}
	\caption[Pascal's triangle divergence]{Illustration of the calculation of the first 6 rows of coefficients of the divergence of Pascal's triangle; emphasizing the coefficients in $F_n$.}
	\label{fig:pascaldivergence}
\end{figure}

Assuming that $\frac{\partial^2 X}{\partial x \partial y},\frac{\partial^2 X}{\partial y \partial x}$ 
are continuous we have, by corollary to Clairaut's theorem, that $\frac{\partial^2 e^X}{\partial x \partial y} = \frac{\partial^2 e^X}{\partial y \partial x}$.
We can then compute the Hessian by symmetrizing the partial differential so that 
antisymmetric terms cancel out.

\begin{IEEEeqnarray*}{rCl}
	\frac{1}{2} \left(\frac{\partial^2 e^X}{\partial x \partial y} + \frac{\partial^2 e^X}{\partial y \partial x}\right)
		& = & \frac{1}{2} \frac{\partial}{\partial x} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right) e^X\\
		&   & +\: \frac{1}{2} \frac{\partial}{\partial y} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right) e^X\\
		& = & \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right)\\
		&   & \quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right) e^X\\
		&   & \quad\quad +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial^2 X}{\partial x \partial y} \right) + \frac{\partial^2 X}{\partial x \partial y}\right) e^X\\
		&   & \quad\quad\quad +\: \frac{1}{2} \left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\left[\frac{\partial X}{\partial x}, \frac{\partial X}{\partial y}\right]\right) e^X\\
		&   & \quad\quad\quad\quad +\: \frac{1}{2} \left(\sum_{n=1}^{\infty} \frac{1}{\left(n+2\right)!} \sum_{m=1}^n \operatorname{ad}_X^{n-m} \left[ \frac{\partial X}{\partial x}, \operatorname{ad}_X^{m-1} \frac{\partial X}{\partial y}\right]  \right) e^X\\
		&   & +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right)\\
		&   & \quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right) e^X\\
		&   & \quad\quad +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial^2 X}{\partial y \partial x} \right) + \frac{\partial^2 X}{\partial y \partial x}\right) e^X\\
		&   & \quad\quad\quad +\: \frac{1}{2} \left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\left[\frac{\partial X}{\partial y}, \frac{\partial X}{\partial x}\right]\right) e^X\\
		&   & \quad\quad\quad\quad +\: \frac{1}{2} \left(\sum_{n=1}^{\infty} \frac{1}{\left(n+2\right)!} \sum_{m=1}^n \operatorname{ad}_X^{n-m} \left[ \frac{\partial X}{\partial y}, \operatorname{ad}_X^{m-1} \frac{\partial X}{\partial x}\right]  \right) e^X\\
		& = & \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial^2 X}{\partial x \partial y} \right) + \frac{\partial^2 X}{\partial x \partial y}\right) e^X\\
		&   & +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right)\\
		&   & \quad\quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right) e^X\\
		&   & +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right)\\
		&   & \quad\quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right) e^X\\
		&   & +\: \frac{1}{2} \left(\sum_{n=1}^{\infty} \frac{1}{\left(n+2\right)!} \sum_{m=1}^n \sum_{k=0}^{n-m} \binom{n-m}{k} \left[ \operatorname{ad}_X^k \frac{\partial X}{\partial x}, \operatorname{ad}_X^{n-k-1} \frac{\partial X}{\partial y}\right] \right) e^X\\
		&   & +\: \frac{1}{2} \left(\sum_{n=1}^{\infty} \frac{1}{\left(n+2\right)!} \sum_{m=1}^n \sum_{k=0}^{n-m} \binom{n-m}{k} \left[ \operatorname{ad}_X^k \frac{\partial X}{\partial y}, \operatorname{ad}_X^{n-k-1} \frac{\partial X}{\partial x}\right] \right) e^X\\
		& = & \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial^2 X}{\partial x \partial y} \right) + \frac{\partial^2 X}{\partial x \partial y}\right) e^X\\
		&   & +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right)\\
		&   & \quad\quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right) e^X\\
		&   & +\: \frac{1}{2} \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) + \frac{\partial X}{\partial x}\right)\\
		&   & \quad\quad \cdot \left(\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial y} \right) + \frac{\partial X}{\partial y}\right) e^X
\end{IEEEeqnarray*}

The only terms requiring approximation are precisely the approximation we 
derived in the previous section. Reusing the components in the algorithm in the
previous section we can present an algorithm for the Hessian.