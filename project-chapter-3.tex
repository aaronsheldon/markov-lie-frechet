\chapter{Pad\'{e} Approximation of the Fr\'{e}chet Derivatives of the Exponential Map}
\section{The Gradient}
In ??, and revisited in ?? ?? reviewed algorithms for calculating the matrix 
exponential. Recently ?? optimized the Pad\'{e} approximation of the matrix 
exponential for numerical computing on modern $64$ bit architectures. In ?? an 
algorithm to approximate the derivative of the matrix exponential was for 
formulated, essentially by taking the derivative of the Pad\'{e} approximation 
of the matrix exponential and then working out a recursive calculation for the
derivatives of the powers of a matrix.

While the derivative of the Pad\'{e} approximation of an analytic function will 
converge to the derivative of the analytic function, it is not true that the
derivative of the Pad\'{e} approximation of an analytic function is the Pad\'{e} 
approximation of the derivative of an analytic function. In the sense that 
Pad\'{e} approximations of analytic functions are an optimal series algebraic 
approximations the method proposed in ?? is not optimal.

In this chapter we will develop an approximation for the first and second order
Fr\'{e}chet derivatives of the matrix exponential by first factoring the 
derivative into a component that holds for the commutative condition and a 
second component containing the anomaly due to non-commutative. we will then
derive the Pad\'{e} approximation for the anomaly. We begin by listing the eight 
forms of the Fr\'{e}chet derivative of exponential map, in the direction $\frac{\partial X}{\partial x}$
at the point $X$ in the Lie algebra.
\footnote{We have abused and confounded the notations for directional 
derivatives and partial derivatives here by assuming that $X$ is parameterized 
by $x$ so that $\frac{\partial e^X}{\partial x}$ is the derivative in the
direction of change of $x$.}
\footnote{With respect to the adjoint operator, we are using the currying 
partial application notation of $\left[L f\left(\cdotp\right)\right]\left(y\right)$
to indicate the application of the operator $L$ to $f\left(x\right)$ followed by
evaluation of the result at $y$.}

{\setlength{\IEEEnormaljot}{18pt}
\begin{IEEEeqnarray*}{rClls}
	\frac{\partial e^X}{\partial x}
		& = & e^X \left[\int_0^1 e^{- \operatorname{ad}_{sX} \cdotp} ds \right] \left(\frac{\partial X}{\partial x}\right) & & \\
		& = & e^X \left[\frac{1 - e^{-\operatorname{ad}_X \cdotp}}{\operatorname{ad}_X \cdotp}\right]\left(\frac{\partial X}{\partial x}\right) & \smash{\left. \IEEEstrut[4\jot] \right\rbrace} & \text{left recursive} \\
		& = & e^X \left[\sum_{n=0}^{\infty} \frac{\left(-1\right)^n}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\frac{\partial X}{\partial x}\right) & & \\
		& = & \left[ \frac{\operatorname{ad}_{e^X} \cdotp}{\operatorname{ad}_X \cdotp} \right]\left(\frac{\partial X}{\partial x}\right) & & \text{adjoint ratio} \\
		& = & e^{\frac{1}{2}X} \left[ \frac{e^{\frac{1}{2}\operatorname{ad}_X \cdotp } - e^{-\frac{1}{2}\operatorname{ad}_X \cdotp}}{\operatorname{ad}_X \cdotp} \right]\left(\frac{\partial X}{\partial x}\right) e^{\frac{1}{2}X} & & \text{hyperbolic} \\
		& = & \left[ \int_0^1 e^{\operatorname{ad}_{sX} \cdotp} ds \right]\left(\frac{\partial X}{\partial x}\right) e^X & &\\
		& = & \left[ \frac{e^{\operatorname{ad}_X \cdotp} - 1}{\operatorname{ad}_X \cdotp} \right] \left(\frac{\partial X}{\partial x}\right) e^X & \smash{\left. \IEEEstrut[4\jot] \right\rbrace} & \text{right recursive}\\
		& = & \left[\sum_{n=0}^{\infty} \frac{1}{\left(n+1\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\frac{\partial X}{\partial x} \right) e^X & &
\end{IEEEeqnarray*}}

The last equality demonstrates the anomaly term most clearly; where the first
multiplicative factor in the derivative accounts for any lack of commutativity 
between $X$ and $\frac{\partial X}{\partial x}$. This can be seen clearly when 
considering the condition $\left[X,\frac{\partial X}{\partial x}\right]=0$ 
in which case $\frac{\partial e^X}{\partial x} = \frac{\partial X}{\partial x} e^X$. 

Even though the factorization provides a transparent representation of the 
computational terms, multiplication is less numerically stable than addition. We 
can improve the numerical stability by decomposing the first multiplicative 
factor into a linear sum of an anomaly term that will be $0$ when $\left[X,\frac{\partial X}{\partial x}\right]=0$, 
and an invariant term that will be non-negligible for all $X$.

\begin{IEEEeqnarray*}{rCl}
	\frac{\partial e^X}{\partial x}
		& = & \left[\frac{e^{\operatorname{ad}_X \cdotp} - 1 - \operatorname{ad}_X \cdotp }{\operatorname{ad}_X^2 \cdotp} \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right) e^X + \frac{\partial X}{\partial x} e^X\\
		& = & \underbrace{\left[\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \operatorname{ad}_X^n \cdotp \right] \left(\operatorname{ad}_X \frac{\partial X}{\partial x} \right)}_{\text{non-commutative anomaly}} e^X + \underbrace{\frac{\partial X}{\partial x}}_{\text{invariant}} e^X
\end{IEEEeqnarray*}

The anomaly term is linear in $\frac{\partial X}{\partial x}$ and is a power 
series in $\operatorname{ad}_X \cdotp$, thus we need a Pad\'{e} approximation in 
$\operatorname{ad}_X \cdotp$. While it is clear that $f\left(x\right) : x \mapsto \frac{e^{x} -1 - x}{x^2}$ 
is analytic for $x \in \mathbb{R}$ or $x \in \mathbb{C}$, the powers of
$\operatorname{ad}_X \cdotp$ require more careful consideration.

The operator $\operatorname{ad}_X \cdotp$ has tensorial relationships to the 
underlying vector space on which $X$ is a linear operator. Specifically $\operatorname{ad}_X \cdotp$
is a bounded, and thus continuous, linear operator, such that if the underlying 
vector space is $n$ dimensional then the vector space of linear operators is 
$n^2$ dimensional, and $\operatorname{ad}_X \cdotp$ by tensor extension can be 
represented as an $n^2 \times n^2$ matrix. 

Computational the powers of $\operatorname{ad}_X \cdotp$ can be calculated 
through the Kronecker representation, which requires representing the matrices 
as vectors. The vector representation of a matrix is achieved by the matrix 
reshaping  operator $\operatorname{vec}\left(Y\right) = \vec{y}$, which forms a 
vector $\vec{y}$ by concatenation of the columns of $Y$, called vectorization. 
We denote the inverse operator to vectorization $\operatorname{mat}\left(\vec{y}\right) = \operatorname{vec}^{-1}\left(\vec{y}\right) = Y$,
which reshapes a vector, $n^2$, into an $n \times n$ matrix.

After juggling the indexes of $\operatorname{vec}\left(\frac{\partial X}{\partial x}\right)$, 
the Kronecker representation follows as

\begin{IEEEeqnarray*}{rCl}
	\operatorname{ad}_X \frac{\partial X}{\partial x} 
		& = & \operatorname{mat}\left( \left(I \otimes X - X \otimes I \right) \operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right)
\end{IEEEeqnarray*}

Proceeding by induction we find that 

\begin{IEEEeqnarray*}{rCl}
	\operatorname{ad}_X^n \frac{\partial X}{\partial x} 
		& = & \operatorname{mat}\left(\left(I \otimes X - X \otimes I \right)^n\operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right)
\end{IEEEeqnarray*}

It follows that $\frac{\partial e^X}{\partial x}$ can be computed by

\begin{IEEEeqnarray*}{rCl}
	\frac{\partial e^X}{\partial x}
		& = & \operatorname{mat}\left(\sum_{n=0}^{\infty} \frac{1}{\left(n+2\right)!} \left(I \otimes X - X \otimes I \right)^n \operatorname{vec}\left(\frac{\partial X}{\partial x}\right)\right) e^X + \frac{\partial X}{\partial x} e^X
\end{IEEEeqnarray*}

% break the algorithm into two parts, Pade and anomaly
% need table of [20/20] coefficients.

% Consider parameterization sub-manifold in Lie algebra, algebraic closure
% guareentees finite computations will be in Lie group. Furthermore because
% polytope is in closure, limits will be proper row sum, but might lose invertibility

\section{The Hessian}