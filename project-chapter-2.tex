\chapter{The Lie Algebra of the Generators of Continuous Time Markov Processes}
\section{Stochastic Matrices}
The classical Lie algebras of physics, like the infinitesimal symmetries
of the special unitary algebra $\mathfrak{su}(n)$, are defined with respect to
invariants of a Banach algebra, such as the matrix invariants of the 
determinant, trace, or norm. In contrast stochastic matrices are always 
characterized with respect to a specific unit vector, which we will denote 
$\hat{\mathbbm{1}}$. In the next two subsections we provide an explicit 
construction and characterization of the Lie algebra of stochastic matrices, 
building on the original the work of ??.

The common approach to stochastic matrices begins with the restriction that the 
matrices have positive entries with respect to the standard orthonormal basis 
for the vector space on which it acts; namely $\left\langle\hat{e}_i,A \hat{e}_j\right\rangle \ge 0$
for all $i,j$. In addition to allowing for singular matrices this poses an 
immediate obstacle to the necessary closure with respect to matrix inversion 
required for matrix groups. As the inverse of a stochastic matrix need not have 
non-negative entries with respect to the standard orthonormal basis. 

For the moment we will set aside the non-negative entries restriction, and 
instead begin with a generalization of the concept of fixed row sums. We will 
show this generalization is preserved by matrix inversion, and then develop an 
orthonormal basis from which specific matrices with positive entries, with 
respect to the basis, can be constructed. In essence tackling the problem from 
the reverse direction, starting with the more general idea of fixed row sums, 
then specifying to matrices with positive entries with respect to a constructed 
orthonormal basis.

\begin{definition}
	A matrix $A$ is stochastic with respect to the unit vector $\hat{\mathbbm{1}}$ 
	if $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$
\end{definition}

In an $n$ dimensional vector space the vector $\vec{\mathbbm{1}} = \sqrt{n} \hat{\mathbbm{1}}$ 
acts as the row sum operator on matrices stochastic with respect to $\hat{\mathbbm{1}}$. 
We will make this claim more precise after we dispense with a few more 
foundational definitions.

\begin{definition}
	Let $St(\hat{\mathbbm{1}})$ denote the stochastic Lie group of invertible 
	matrices stochastic with respect to $\hat{\mathbbm{1}}$
\end{definition}

It is tempting to view the name stochastic Lie group has a bait and switch, or 
at least an abuse of the terminology, given we have removed the usual convex
polytope stochastic matrices and replaced it with a group of invertible 
matrices with a common eigenvector $\hat{\mathbbm{1}}$. Previous authors have 
denoted the convex polytope of stochastic matrices as the stochastic semi-group 
and the group invertible matrices as the pseudo-stochastic Lie group. One could 
even consider incorporating Markov into the name, in reference to the fact that 
the transition matrices of a continuous Markov process on a finite state space 
are by definition invertible and have common eigenvector $\hat{\mathbbm{1}}$. 
However the suffix of Lie group in the name connotes both sufficient additional 
restrictions to make the name distinct, and still allows for an indication of a 
relationship with the original concept. Of course, this definition immediately 
necessitates proof of the claim embedded in the definition.

\begin{lemma}
	$St(\hat{\mathbbm{1}})$ is a Lie group
\end{lemma}

\begin{proof}
	We proceed by working mechanistically through the Lie group axioms.
	\begin{enumerate}
		\item The identity element $I$ is in $St(\hat{\mathbbm{1}})$. Clearly $I$ is
		invertible and $I \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		\item If $A,B \in St(\hat{\mathbbm{1}})$ then $AB \in St(\hat{\mathbbm{1}})$. 
		This follows from the computation $AB \hat{\mathbbm{1}} = A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		\item If $A \in St(\hat{\mathbbm{1}})$ then $A^{-1} \in St(\hat{\mathbbm{1}})$.
		Recognize that $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ implies $\hat{\mathbbm{1}} = A^{-1} A \hat{\mathbbm{1}} = A^{-1} \hat{\mathbbm{1}}$.
		\item Associativity follows from $St(\hat{\mathbbm{1}})$ being a subgroup of $GL\left(n\right)$.
		\item Finally, that the matrix product $A^{-1}B$ is smooth for all $A,B \in St(\hat{\mathbbm{1}})$
		likewise follows from $St(\hat{\mathbbm{1}}) < GL\left(n\right)$
	\end{enumerate}
\end{proof}

That $St(\hat{\mathbbm{1}})$ is a proper matrix Lie group implies that it must be
infinitesimal generated by elements of a Lie algebra.

\begin{definition}
	Let $\mathfrak{st}(\hat{\mathbbm{1}})$ denote the stochastic Lie algebra of $St(\hat{\mathbbm{1}})$
\end{definition}

By infinitesimally generated we mean that every element of $St(\hat{\mathbbm{1}})$
is a matrix exponential of some element in $\mathfrak{st}(\hat{\mathbbm{1}})$. 
We can fully characterize this algebra as the set of matrices such that their 
row sums are zero with respect to $\hat{\mathbbm{1}}$.

\begin{lemma}
	The algebra $\mathfrak{st}(\hat{\mathbbm{1}})$ is exactly the set of all 
	matrices with $\hat{\mathbbm{1}}$ in their kernel.
\end{lemma}

\begin{proof}
	Working through the forward and backward inclusions we have
	\begin{enumerate}
		\item Suppose $A \hat{\mathbbm{1}} = 0$ then from the definition of the 
		matrix exponential we have:
		\begin{IEEEeqnarray*}{rCl}
			\exp\left(A\right) \hat{\mathbbm{1}}
				& = & \sum_{n=0}^{\infty} \frac{1}{n!} A^n \hat{\mathbbm{1}}\\
				& = & \hat{\mathbbm{1}} + \sum_{n=1}^{\infty} \frac{1}{n!} 0\\
				& = & \hat{\mathbbm{1}}
		\end{IEEEeqnarray*}
		Thus $\exp\left(A\right) \in St(\hat{\mathbbm{1}})$ implying that $A \in \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Now begin with the reverse assumption, that $A \in \mathfrak{st}(\hat{\mathbbm{1}})$.
		For all $t \in \mathbb{R}$ we have $\exp\left(tA\right) \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		Differentiation with respect to $t$ and evaluation at $t = 0$ yields
		\begin{IEEEeqnarray*}{rCl}
			0 & = & \left. \frac{d}{dt} \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & \left. \frac{d}{dt} \exp\left(tA\right) \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & \left. \exp\left(tA\right) A \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & A \hat{\mathbbm{1}}
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{proof}

Over an $n$ dimensional vector space, the condition on a matrix $A$ that $A \hat{\mathbbm{1}} = 0$
places $n$ constraints on the $n^2$ dimensions of $A$. This leaves $n^2 - n$ 
free dimensions on $\mathfrak{st}(\hat{\mathbbm{1}})$, when considered as a
vector space. This hints that we can construct a generator of $\mathfrak{st}(\hat{\mathbbm{1}})$
from order pairs of basis elements $\hat{e}_i$ for the vector space of $\hat{\mathbbm{1}}$.
To see how this is done we first construct a useful basis for the vector space
of $\hat{\mathbbm{1}}$.

\begin{lemma}
	There exists an orthonormal basis $\hat{e}_i$ such that $\left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n}}$
	for all $i$
\end{lemma}

\begin{proof}
	While a basis with the stipulated properties can be constructed through the
	Gram-Schmidt process, the proof of the existence of such a basis proceeds by
	induction.
	\begin{enumerate}
		\item For $n=1$ the desired basis is precisely the trivial set $\left\lbrace \hat{\mathbbm{1}} \right\rbrace$ 
		which satisfies the condition that $\left\langle \hat{\mathbbm{1}}, \hat{\mathbbm{1}} \right\rangle = 1$
		\item Assume the claim is true for $n$. For $n+1$ pick a unit vector $\hat{e}_{\perp}$
		that is orthogonal to $\hat{\mathbbm{1}}$ and construct the unit vector
		$\hat{e}_{n+1} = \frac{1}{\sqrt{n+1}} \hat{\mathbbm{1}} + \sqrt{\frac{n}{n+1}} \hat{e}_{\perp}$.
		Clearly $\hat{e}_{n+1}$ satisfies the condition $\left\langle \hat{e}_{n+1}, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n+1}}$.
		Next construct a new row sum unit vector $\hat{\mathbbm{1}}_n$ in one 
		dimension lower by projecting onto the subspace orthogonal to $\hat{e}_{\perp}$ 
	\end{enumerate}
\end{proof}

We can now proceed with the central result that motivates this chapter.

\begin{theorem}
	The canonical generators of $\mathfrak{st}(\hat{\mathbbm{1}})$ are 
	$C_{ij} = \frac{1}{\sqrt{2}} \hat{e}_i \otimes \left( \hat{e}_j - \hat{e}_i \right)$
\end{theorem}

\begin{proof}
	To prove that the smallest algebra that contains $C_{ij}$ is $\mathfrak{st}(\hat{\mathbbm{1}})$ 
	it suffices to prove that matrices $C_{ij}$ from a basis for $\mathfrak{st}(\hat{\mathbbm{1}})$.
	This is because a necessary condition for an algebra to contain the matrices
	$C_{ij}$ is that it must contain all sums of the matrices $C_{ij}$. If one
	could sum their way out of the algebra then it would not be an algebra.
	\begin{enumerate}
		\item That $\mathfrak{st}(\hat{\mathbbm{1}})$ is an $n^2-n$ dimensional 
		vector space should be clear from the previous discussion. A full formal
		proof of this claim is found through induction on the dimension $n$.
		\item The matrices $C_{ij}$ are in $\mathfrak{st}(\hat{\mathbbm{1}})$. From
		the definition of the canonical generators
		\begin{IEEEeqnarray*}{rCl}
			C_{ij} \hat{\mathbbm{1}}
				& = & \frac{1}{\sqrt{2}} \hat{e}_i \otimes \left( \hat{e}_j - \hat{e}_i \right) \hat{\mathbbm{1}}\\
				& = & \frac{1}{\sqrt{2}} \hat{e}_i \left( \left\langle \hat{e}_j, \hat{\mathbbm{1}} \right\rangle - \left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle \right)\\
				& = & \frac{1}{\sqrt{2}} \hat{e}_i \left(\frac{1}{\sqrt{n}} - \frac{1}{\sqrt{n}}\right)\\
				& = & 0
		\end{IEEEeqnarray*}
		\item $C_{ij}$ is a set of $n^2-n$ linear independent matrices and so must
		form a basis for all of $\mathfrak{st}(\hat{\mathbbm{1}})$. Again the formal 
		proof of this claim is found through induction on the dimension $n$.
	\end{enumerate}
\end{proof}

The previous theorem serves as the definition of a set of canonical generators 
of $\mathfrak{st}(\hat{\mathbbm{1}})$, the $\frac{1}{\sqrt{2}}$ factor just a 
pleasant normalization constant for the vector $\hat{e}_j - \hat{e}_i$. It is 
important to note that neither the basis $\hat{e}_i$ nor the canonical 
generators $C_{ij}$ are unique. They are uniquely defined only up to rotations 
orthogonal to the vector $\hat{\mathbbm{1}}$.

Before moving on it is worth briefly revisiting the distinction between the 
standard convex polytope of stochastic matrices and the stochastic Lie group, to
develop some physical intuition into the relationship between the two sets of
matrices which have a non-trivial and geometrical interesting intersection.

% need to keep going look at n=2,3

The first result from this theorem is the ability to calculate the structure
constants of the generators of the algebra. We proceed by studying the products
of the generators.

\begin{corollary}
	$C_{ij}C_{kl} = \delta$
\end{corollary}

Which taking the commuators yields the structure constants.

\begin{corollary}
	$\exp\left(C_{ij}\right) = e$
\end{corollary}

% The basis elements represent the states of a continuous markov process.
% When the multipliers of the canonical generators are postive, this gives a
% proper transition matrix for a continuous Markov process. The reverse is 
% also true (needs proof)

\section{Doubly Stochastic Matrices}
Doubly stochastic matrices require double conservation of the vector $\hat{\mathbbm{1}}$, leaving
only $\left(n - 1\right)^2$ linear degrees of freedom. This is an important clue in the construction
of a canonical representation. In fact the representation can be found by choosing one additional
vector $\hat{e}_n$ to ``omit''. This vector plays a similar role to the diagonal in the previous
construction and is used to balance the row and column sums back to zero.
$St(\hat{\mathbbm{1}},\hat{\mathbbm{1}})$ and $\mathfrak{st}(\hat{\mathbbm{1}},\hat{\mathbbm{1}})$