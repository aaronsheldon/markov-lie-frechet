\chapter{The Lie Algebra of Markov Processes Generators}
\section{Stochastic Matrices}
The classical Lie algebras of physics, like the infinitesimal symmetries
of the special unitary algebra $\mathfrak{su}(n)$, are defined with respect to
invariants of a Banach algebra, such as the matrix invariants of the 
determinant, trace, or norm. In contrast stochastic matrices are always 
characterized with respect to a specific unit vector, which we will denote 
$\hat{\mathbbm{1}}$. In the next two sections we provide an explicit 
construction and characterization of the Lie algebra of stochastic matrices, 
building on the original the work of Johnson\cite{johnson_markovtype_1985}.

The common approach to stochastic matrices begins with the restriction that the 
matrices have non-negative entries with respect to the standard orthonormal 
basis for the vector space on which it acts; namely $\left\langle\hat{e}_i,A \hat{e}_j\right\rangle \ge 0$
for all $i,j$. In addition to allowing for singular matrices, this poses an 
immediate obstacle to the necessary closure with respect to matrix inversion 
required for matrix groups; as the inverse of a stochastic matrix need not have 
non-negative entries with respect to the standard orthonormal basis. 

For the moment we will set aside the restriction that the entries be 
non-negative, and instead begin with a generalization of fixed row sums to 
abstract linear operators. We will show that this generalization is preserved by 
operator inversion, and then develop an orthonormal basis from which matrix 
representations of the abstract linear operators can be constructed with 
non-negative entries. In essence tackling the problem from the reverse 
direction, starting with the an abstract generalization of the idea of fixed row 
sums, and then specifying matrices with non-negative entries with respect to a 
constructed orthonormal basis.

\begin{definition}
	A bounded linear operator $A$ on a finite dimensional Hilbert space is 
	stochastic with respect to the unit vector $\hat{\mathbbm{1}}$ if $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$
\end{definition}

Note that this definition does not stipulate any conditions on non-singularity,
and thus includes, as representations of the linear operators, all the matrices 
in the convex polytope of stochastic matrices. For an $n$ dimensional vector 
space the vector $\vec{\mathbbm{1}} = \sqrt{n} \hat{\mathbbm{1}}$ acts as the 
row sum operator on bounded linear operators stochastic with respect to $\hat{\mathbbm{1}}$. 
We will make this claim more precise after we dispense with a few more 
foundational definitions.

\begin{definition}
	Let $St(\hat{\mathbbm{1}})$ denote the stochastic Lie group of invertible 
	bounded linear operators stochastic with respect to $\hat{\mathbbm{1}}$.
\end{definition}

It is tempting to view the name stochastic Lie group as a bait and switch, or 
at least an abuse of the terminology, given we have removed the usual convex
polytope of stochastic matrices and replaced it with a group of invertible 
bounded linear operators with a common eigenvector $\hat{\mathbbm{1}}$. Previous 
authors ?? have denoted the convex polytope of stochastic matrices as the 
stochastic semi-group, and the group of invertible matrices as the 
pseudo-stochastic Lie group. One could even consider incorporating Markov into 
the name, in reference to the fact that the transition matrices of a continuous 
time homogeneous Markov process on a finite state space are by definition 
invertible, and have common eigenvector $\hat{\mathbbm{1}}$. However the suffix 
of Lie group in the name connotes both sufficient additional restrictions to 
make the name distinct, and still allows for an indication of a relationship 
with the original concept. Of course, this definition immediately necessitates a
proof of the claim embedded in the definition.

\begin{lemma}
	$St(\hat{\mathbbm{1}})$ is a Lie group
\end{lemma}

\begin{IEEEproof}
	We proceed by working mechanistically through the Lie group axioms\cite{hall_lie_2004}.
	\begin{enumerate}
		\item The identity element $I$ is in $St(\hat{\mathbbm{1}})$. Clearly $I$ is
		invertible and $I \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		\item If $A,B \in St(\hat{\mathbbm{1}})$ then $AB \in St(\hat{\mathbbm{1}})$. 
		This follows from the computation $AB \hat{\mathbbm{1}} = A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		\item If $A \in St(\hat{\mathbbm{1}})$ then $A^{-1} \in St(\hat{\mathbbm{1}})$.
		Recognize that $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ implies $\hat{\mathbbm{1}} = A^{-1} A \hat{\mathbbm{1}} = A^{-1} \hat{\mathbbm{1}}$.
		\item Associativity follows from $St(\hat{\mathbbm{1}})$ being a subgroup of $GL\left(n\right)$.
		\item Finally, we need to prove that is $St(\hat{\mathbbm{1}})$ closed 
		within $GL\left(n\right)$. Consider a sequence $A_n \in St(\hat{\mathbbm{1}})$ 
		that converges to $A$, then $\hat{\mathbbm{1}} = A_n \hat{\mathbbm{1}} \rightarrow A \hat{\mathbbm{1}}$. 
		Now if $A$ is invertible then we are done, and if $A$ is not invertible then 
		$A \notin GL\left(n\right)$, again satisfying closure within $GL\left(n\right)$.\hfill\IEEEQEDhere
	\end{enumerate}
\end{IEEEproof}

That $St(\hat{\mathbbm{1}})$ is a proper Lie group implies that it must be
infinitesimal generated by elements of a Lie algebra.

\begin{definition}
	Let $\mathfrak{st}(\hat{\mathbbm{1}})$ denote the stochastic Lie algebra of $St(\hat{\mathbbm{1}})$
\end{definition}

By infinitesimally generated we mean that every element of $St(\hat{\mathbbm{1}})$
is the exponential map of at least one element in $\mathfrak{st}(\hat{\mathbbm{1}})$. 
We can fully characterize this algebra as the set of bounded linear operators 
such that $\hat{\mathbbm{1}}$ is in the kernel of each operator.

\begin{lemma}
	The algebra $\mathfrak{st}(\hat{\mathbbm{1}})$ is exactly the set of all 
	bounded linear operators with $\hat{\mathbbm{1}}$ in their kernel.
\end{lemma}

\begin{IEEEproof}
	Working through the forward and backward inclusions we have
	\begin{enumerate}
		\item Suppose $A \hat{\mathbbm{1}} = 0$ then from the definition of the 
		exponential map we have:
		\begin{IEEEeqnarray*}{rCl}
			\exp\left(A\right) \hat{\mathbbm{1}}
				& = & \sum_{n=0}^{\infty} \frac{1}{n!} A^n \hat{\mathbbm{1}}\\
				& = & \hat{\mathbbm{1}} + \sum_{n=1}^{\infty} \frac{1}{n!} 0\\
				& = & \hat{\mathbbm{1}}
		\end{IEEEeqnarray*}
		Thus $\exp\left(A\right) \in St(\hat{\mathbbm{1}})$ implying that $A \in \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Now begin with the reverse assumption, that $A \in \mathfrak{st}(\hat{\mathbbm{1}})$.
		For all $t \in \mathbb{R}$ we have $\exp\left(tA\right) \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$.
		Differentiation with respect to $t$ and evaluation at $t = 0$ yields
		\begin{IEEEeqnarray*}{+rCl+x*}
			0 & = & \left. \frac{d}{dt} \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & \left. \frac{d}{dt} \exp\left(tA\right) \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & \left. \exp\left(tA\right) A \hat{\mathbbm{1}} \right|_{t=0}\\
				& = & A \hat{\mathbbm{1}} & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

The following chapter will hinge on taking the derivatives of parameterizations
$X : \mathbb{R}^k \mapsto \mathfrak{st}(\hat{\mathbbm{1}})$. The principle role
of this chapter is to assure ourselves that we will not differentiate ourselves
out of $\mathfrak{st}(\hat{\mathbbm{1}}$. The next corollary nicely provides
just such an assurance:

\begin{corollary}
	The tangent space $T\mathfrak{st}(\hat{\mathbbm{1}}) = \mathfrak{st}(\hat{\mathbbm{1}})$
\end{corollary}

\begin{IEEEproof}
	The proof is complementary to the preceding lemma and moves through each 
	direction of inclusion:
	\begin{enumerate}
		\item To show that $\mathfrak{st}(\hat{\mathbbm{1}})\subseteq T\mathfrak{st}(\hat{\mathbbm{1}})$
		consider $X\left(x\right) = x X_0$ where $x$ is a scalar parameter and $X_0 \in \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Clearly $X\left(x\right) \in \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Furthermore the tangent $\frac{\partial}{\partial x} X\left(x\right) = X_0 \in \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Now to show that $T \mathfrak{st}(\hat{\mathbbm{1}}) \subseteq \mathfrak{st}(\hat{\mathbbm{1}})$
		we start with an arbitrary smooth parameterization $X\left(x\right) : \mathbb{R}^k \mapsto \mathfrak{st}(\hat{\mathbbm{1}})$
		\item Using the same trick of differentiation we have
		\begin{IEEEeqnarray*}{+rCl+x*}
			0 & = & \frac{\partial}{\partial x} 0\\
				& = & \frac{\partial}{\partial x} \left( X\left(x\right) \hat{\mathbbm{1}}\right)\\
				& = & \left(\frac{\partial}{\partial x} X\left(x\right)\right) \hat{\mathbbm{1}} & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

Clearly the tangent space to a normed vector space is the normed vector space.
After all one can just choose a fixed basis and then differentiate the 
individual parameterized in products. However the preceding corollary was 
presented in its form to illustrate the intuition that any increase in a 
particular element has to be compensated for by an equal decrease in some other
elements.

Over an $n$ dimensional vector space, the condition on a matrix $A$ that $A \hat{\mathbbm{1}} = 0$
places $n$ constraints on the $n^2$ dimensions of $A$. This leaves $n^2 - n$ 
free dimensions on $\mathfrak{st}(\hat{\mathbbm{1}})$, when considered as a
vector space. This hints that we can construct a generator of $\mathfrak{st}(\hat{\mathbbm{1}})$
from order pairs of basis elements $\hat{e}_i$ for the vector space of $\hat{\mathbbm{1}}$.
To see how this is done we first construct a useful basis for the vector space
to which $\hat{\mathbbm{1}}$ is a member.

\begin{lemma}
	There exists an orthonormal basis $\hat{e}_i$ such that $\left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n}}$
	for all $i$
\end{lemma}

\begin{IEEEproof}
	While a basis with the stipulated properties can be constructed through the
	Gram-Schmidt process, the proof of the existence proceeds by induction.
	\begin{enumerate}
		\item For $n=1$ the desired basis is precisely the trivial set $\left\lbrace \hat{\mathbbm{1}} \right\rbrace$ 
		which satisfies the condition that $\left\langle \hat{\mathbbm{1}}, \hat{\mathbbm{1}} \right\rangle = 1$.
		\item Assume the claim is true for $n$. For $n+1$ pick a unit vector $\hat{e}_{\perp}$
		that is orthogonal to $\hat{\mathbbm{1}}$ and construct the unit vector
		$\hat{e}_{n+1} = \frac{1}{\sqrt{n+1}} \hat{\mathbbm{1}} + \sqrt{\frac{n}{n+1}} \hat{e}_{\perp}$.
		Clearly $\hat{e}_{n+1}$ satisfies the condition $\left\langle \hat{e}_{n+1}, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n+1}}$.
		\item To use the the induction assumption we construct a new row sum unit 
		vector $\hat{\mathbbm{1}}_n = \sqrt{\frac{n+1}{n}}\hat{\mathbbm{1}} - \frac{1}{\sqrt{n}}\hat{e}_{n+1}$ 
		in one dimension lower by projecting onto the subspace orthogonal to $\hat{e}_{n+1}$.
		\item By the induction assumption there exists a basis $\hat{e}_i$ with $i \le n$, 
		such that $\left\langle \hat{e}_i, \hat{\mathbbm{1}}_n \right\rangle = \frac{1}{\sqrt{n}}$.
		\item Because $\hat{e}_i$ with $i \le n$ was constructed in the space 
		orthogonal to $\hat{e}_{n+1}$ if follows that $\left\langle \hat{e}_i, \hat{e}_j \right\rangle = \delta_{ij}$
		for all $i,j \le n+1 $.
		\item Then using the definitions of $\hat{e}_{n+1}$ and $\hat{\mathbbm{1}}_n$
		we can calculate the inner product $\left\langle \hat{e}_i, \hat{\mathbbm{1}}_n \right\rangle$
		for $i \le n$
		\begin{IEEEeqnarray*}{rCl}
			\frac{1}{\sqrt{n}}
				& = & \left\langle \hat{e}_i, \hat{\mathbbm{1}}_n \right\rangle\\
				& = & \sqrt{\frac{n+1}{n}} \left\langle \hat{e}_j, \hat{\mathbbm{1}} \right\rangle - \frac{1}{\sqrt{n}} \left\langle \hat{e}_i, \hat{e}_{n+1} \right\rangle\\
				& = & \sqrt{\frac{n+1}{n}} \left\langle \hat{e}_j, \hat{\mathbbm{1}} \right\rangle
		\end{IEEEeqnarray*}
		Inverting the fraction in the equality yields $\left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n+1}}$
		for all $i \le n+1$.\hfill\IEEEQEDhere
	\end{enumerate}
\end{IEEEproof}

As a direct result of the construction of the basis vectors $\hat{e}_i$ we see 
that $\vec{\mathbbm{1}} = \sum_{i=1}^n \hat{e}_i$. Thus $\vec{\mathbbm{1}}$ can
be interpreted as the row sum vector in basis $\hat{e}_i$.

The constructed basis leads naturally to considering the minimal non-trivial 
matrices $C_{ij} = \hat{e}_i \otimes \left( \hat{e}_j - \hat{e}_i \right)$ as 
holding significance in the structure of $\mathfrak{st}(\hat{\mathbbm{1}})$.
In fact this will be the central result of this chapter: that the algebraic 
closure of the matrices $C_{ij}$ is the stochastic Lie algebra $\mathfrak{st}(\hat{\mathbbm{1}})$. 
To establish this result we need a preliminary result that proves the 
commutators $\left[C_{ij},C_{kl}\right]$ are linear combinations of matrices $C_{ij}$.

\begin{lemma}
	\begin{IEEEeqnarray*}{rCl}
		C_{ij}C_{kl} & = &
		\begin{cases}
			- C_{il} & i=k,\\
			C_{il} - C_{ij} & j=k,\\
			0 & \text{otherwise}.
		\end{cases}
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	We proceed in two steps; calculating the terms of the products, then 
	simplifying the cases, always assuming $i \neq j$ and $k \neq l$.
	\begin{enumerate}
		\item Term wise computation of the Kronecker products yields
		\begin{IEEEeqnarray*}{rCl}
			C_{ij}C_{kl}
				& = & \hat{e}_i \otimes \left( \hat{e}_j - \hat{e}_i \right) \hat{e}_k \otimes \left( \hat{e}_l - \hat{e}_k \right)\\
				& = & \hat{e}_i \otimes \hat{e}_j \hat{e}_k \otimes \hat{e}_l + \hat{e}_i \otimes \hat{e}_i \hat{e}_k \otimes \hat{e}_k - \hat{e}_i \otimes \hat{e}_j \hat{e}_k \otimes \hat{e}_k - \hat{e}_i \otimes \hat{e}_i \hat{e}_k \otimes \hat{e}_l\\
				& = & \delta_{jk} \hat{e}_i \otimes \hat{e}_l + \delta_{ik} \hat{e}_i \otimes \hat{e}_k - \delta_{jk} \hat{e}_i \otimes \hat{e}_k - \delta_{ik} \hat{e}_i \otimes \hat{e}_l\\
				& = & \left(\delta_{jk} - \delta_{ik} \right) \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_k \right)
		\end{IEEEeqnarray*}
		\item We work through each case of $\delta_{jk} - \delta_{ik}$, starting 
		with the case $i=k$ 
		\begin{IEEEeqnarray*}{rCl}
			C_{ij}C_{il}
				& = & \left(\delta_{jk} - \delta_{ii} \right) \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_i \right)\\
				& = & - \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_i \right)\\
				& = & - C_{il}
		\end{IEEEeqnarray*}
		\item When $j=k$ we have
		\begin{IEEEeqnarray*}{rCl}
			C_{ij}C_{jl}
				& = & \left(\delta_{jj} - \delta_{ij} \right) \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_j \right)\\
				& = & \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_j \right)\\
				& = & \hat{e}_i \otimes \left( \hat{e_l} - \hat{e}_i + \hat{e}_i - \hat{e}_j \right)\\
				& = & C_{il} - C_{ij}
		\end{IEEEeqnarray*}
		\item Finally when none of the previous conditions apply
		\begin{IEEEeqnarray*}{+rCl+x*}
			C_{ij}C_{kl}
				& = & \left(\delta_{jk} - \delta_{ik} \right) \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_k \right)\\
				& = & 0 \cdot \hat{e}_i \otimes \left( \hat{e}_l - \hat{e}_k \right)\\
				& = & 0 & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

While this result is sufficient to accomplish the central result, it is worth
carrying through with the computation of the structure constants of the generators.

\begin{corollary}
	\begin{IEEEeqnarray*}{rCl}
		\left[C_{ij},C_{kl}\right] & = &
		\begin{cases}
			C_{ij} - C_{il} & i=k,\\
			C_{kj} - C_{ki} & i=l,\\
			C_{il} - C_{ij} & j=k,\\
			0 & \text{otherwise}.
		\end{cases}
	\end{IEEEeqnarray*}
\end{corollary}

\begin{IEEEproof}
	As in the previous lemma we work case wise through the equalities.
	\begin{enumerate}
		\item Starting with $i=k$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ij},C_{il}\right]
				& = & C_{ij}C_{il} - C_{il}C_{ij}\\
				& = & C_{ij} - C_{il}
		\end{IEEEeqnarray*}
		\item For $i=l$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ij},C_{ki}\right]
				& = & C_{ij}C_{ki} - C_{ki}C_{ij}\\
				& = & C_{kj} - C_{ki}
		\end{IEEEeqnarray*}
		\item For $j=k$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ij},C_{jl}\right]
				& = & C_{ij}C_{jl} - C_{jl}C_{ij}\\
				& = & C_{il} - C_{ij}
		\end{IEEEeqnarray*}
		\item When none of the conditions apply
		\begin{IEEEeqnarray*}{+rCl+x*}
			\left[C_{ij},C_{kl}\right]
				& = & C_{ij}C_{kl} - C_{kl}C_{ij}\\
				& = & 0 & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

We can now proceed with the central result that motivates this chapter.

\begin{theorem}
	The canonical generators of $\mathfrak{st}(\hat{\mathbbm{1}})$ are $C_{ij}$
\end{theorem}

\begin{IEEEproof}
	The previous lemma has established that the products, and thus the 
	commutators, of $C_{ij}$ are linear in $C_{ij}$. We then have to prove that 
	the smallest algebra that contains $C_{ij}$ is $\mathfrak{st}(\hat{\mathbbm{1}})$. 
	As thus, it is sufficient to prove that matrices $C_{ij}$ from a basis for $\mathfrak{st}(\hat{\mathbbm{1}})$.
	This is because a necessary condition for an algebra to contain the matrices
	$C_{ij}$ is that it must contain all sums of the matrices $C_{ij}$. If one
	could sum their way out of the algebra then it would not be an algebra.
	\begin{enumerate}
		\item That $\mathfrak{st}(\hat{\mathbbm{1}})$ is an $n^2-n$ dimensional 
		vector space should be clear from the previous discussion. A full formal
		proof of this claim is found through induction on the dimension $n$.
		\item The matrices $C_{ij}$ are in $\mathfrak{st}(\hat{\mathbbm{1}})$. From
		the definition of the canonical generators
		\begin{IEEEeqnarray*}{rCl}
			C_{ij} \hat{\mathbbm{1}}
				& = & \hat{e}_i \otimes \left( \hat{e}_j - \hat{e}_i \right) \hat{\mathbbm{1}}\\
				& = & \hat{e}_i \left( \left\langle \hat{e}_j, \hat{\mathbbm{1}} \right\rangle - \left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle \right)\\
				& = & \hat{e}_i \left(\frac{1}{\sqrt{n}} - \frac{1}{\sqrt{n}}\right)\\
				& = & 0
		\end{IEEEeqnarray*}
		\item $C_{ij}$ is a set of $n^2-n$ linear independent matrices and so must
		form a basis for all of $\mathfrak{st}(\hat{\mathbbm{1}})$. That there are
		only $n^2-n$ matrices is clear from the fact that $C_{ii} = 0$. While the 
		formal proof of linear independence is again found through induction on the 
		dimension $n$.\hfill\IEEEQEDhere
	\end{enumerate}
\end{IEEEproof}

The previous theorem serves as the definition of a set of canonical generators 
of $\mathfrak{st}(\hat{\mathbbm{1}})$. It is  important to note that neither the 
basis $\hat{e}_i$ nor the canonical generators $C_{ij}$ are unique. They are 
uniquely defined only up to rotations orthogonal to the vector $\hat{\mathbbm{1}}$.
Nevertheless we can immediately see by Jacobi's formula that when $G = \sum_{i,j} \alpha_{ij} C_{ij}$ 
then $\det G = \exp\left( \sum_{i,j} \alpha_{ij} \right)$.

Geometrically fixing a basis $\hat{e}_i$ defines a convex polytope in the form
of a unit hypercube $\left[0,1\right]^{n^2-n}$ in the parameter space isomorphic 
to $\mathfrak{st}(\hat{\mathbbm{1}})$. For specificity, we refer to this as the
convex polytope of matrices stochastic with respect to basis $\hat{e}_i$. 
Analytically $St(\hat{\mathbbm{1}})$ is open, yet the boundary of the polytope 
is always a limit point of $St(\hat{\mathbbm{1}})$. In particular every vertex
of the polytope is a limit point of $St(\hat{\mathbbm{1}})$. Probabilistically, 
the constructed basis elements $\hat{e}_i$ are a well defined enumeration of the 
states of a continuous time homogeneous Markov process on a finite state space. 
For example, we can Lie theoretically reformulate the classic two state 
continuous Markov process.

\begin{corollary}
	$\exp\left(\alpha C_{ij} + \beta C_{ji}\right) = I + \frac{1 - e^{-\alpha - \beta }}{\alpha + \beta} \left(\alpha C_{ij} + \beta C_{ji}\right)$
\end{corollary}

\begin{IEEEproof}
	We first work out the powers of $\alpha C_{ij} + \beta C_{ji}$, and then apply
	the calculation to the definition of the matrix exponential.
	\begin{enumerate}
		\item Consider the square of $\alpha C_{ij} + \beta C_{ji}$
		\begin{IEEEeqnarray*}{rCl}
			\left(\alpha C_{ij} + \beta C_{ji}\right)^2
				& = & \alpha^2 C_{ij}^2 + \alpha\beta C_{ij}C_{ji} + \alpha\beta C_{ji}C_{ij} + \beta^2 C_{ji}^2\\
				& = & - \left(\alpha + \beta \right) \left(\alpha C_{ij} + \beta C_{ji}\right)
		\end{IEEEeqnarray*}
		\item It immediately follows that $\left(\alpha C_{ij} + \beta C_{ji}\right)^n = \left(-\alpha - \beta\right)^{n-1}\left(\alpha C_{ij} + \beta C_{ji}\right)$ 
		and thus the exponential is
		\begin{IEEEeqnarray*}{+rCl+x*}
			\exp\left(\alpha C_{ij} + \beta C_{ji}\right)
				& = & I + \sum_{n=1}^{\infty} \frac{1}{n!} \left(-\alpha - \beta\right)^{n-1}\left(\alpha C_{ij} + \beta C_{ji}\right)\\
				& = & I + \frac{1 - e^{-\alpha - \beta }}{\alpha + \beta} \left(\alpha C_{ij} + \beta C_{ji}\right) & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

This last corollary admits a intuitive heuristic interpretation: that each 
canonical generator $C_{ij}$ can be thought of as measuring the infinitesimal 
transition rate, or flow of probability, from the state represented by basis 
element $\hat{e}_i$ to the state represented by the basis element $\hat{e}_j$. 
This can be seen by considering the matrix representation of $\exp\left(\alpha C_{ij}\right)$ 
in the basis spanned by $\hat{e}_i$ and $\hat{e}_j$.

\begin{IEEEeqnarray*}{rCl}
	I + \left(1 - e^{-\alpha} \right)C_{ij}
		& = &
		\begin{pmatrix}
			e^{-\alpha} & 1 - e^{-\alpha}\\
			0 & 1
		\end{pmatrix}
\end{IEEEeqnarray*}

Taking the limit as $\alpha \rightarrow \infty$ shows while the limits in the 
positive directions in the tangent space $\mathfrak{st}(\hat{\mathbbm{1}})$
maybe finite, $St(\hat{\mathbbm{1}})$ is not closed.

\begin{IEEEeqnarray*}{rCl}
	\lim_{\alpha \rightarrow \infty} \exp\left(\alpha C_{ij} \right)
		& = & I + C_{ij}\\
		& = &
		\begin{pmatrix}
			0 & 1\\
			0 & 1
		\end{pmatrix}
\end{IEEEeqnarray*}

The interpretation of $C_{ij}$ as measuring a real flow is more nuanced than may
first appear, as $e^{-\alpha} > 0$ for all $\alpha \in \mathbb{R}$. To realize $e^{-\alpha} < 0$
requires that $\mathbb{I}m\left(\alpha\right) \equiv \pi \bmod 2 \pi$. The 
importance of imaginary numbers becomes clear when considering the exponential 
of the generator $\alpha \left(C_{ij} + C_{ji}\right)$.

\begin{IEEEeqnarray*}{rCl}
	\exp\left(\alpha \left(C_{ij} + C_{ji}\right)\right)
		& = & I + \frac{1-e^{-2\alpha}}{2}\left(C_{ij} + C_{ji}\right)
\end{IEEEeqnarray*}

Taking the positive limit of $\alpha$ yields an open limit point on the boundary
of $St(\hat{\mathbbm{1}})$, but still in the the convex polytope of stochastic 
matrices with respect to basis $\hat{e}_i$.

\begin{IEEEeqnarray*}{rCl}
	\lim_{\alpha \rightarrow \infty} \exp\left(\alpha \left(C_{ij} + C_{ji}\right)\right)
		& = & I + \frac{1}{2}\left(C_{ij} + C_{ji}\right)\\
		& = & \frac{1}{2}
		\begin{pmatrix}
			1 & 1\\
			1 & 1
		\end{pmatrix}
\end{IEEEeqnarray*}

However not all matrices inside the convex polytope are realized by positive 
values of $\alpha$. For example to find the invertible vertex of the convex 
polytope on the line $\alpha$, we need to consider $\alpha = \mathrm{i}\frac{\pi}{2}$.

\begin{IEEEeqnarray*}{rCl}
	\exp\left(\alpha \left(C_{ij} + C_{ji}\right)\right)
		& = & I + \frac{1-e^{- \mathrm{i} \pi}}{2}\left(C_{ij} + C_{ji}\right)\\
		& = & I + \left(C_{ij} + C_{ji}\right)\\
		& = &
		\begin{pmatrix}
			0 & 1\\
			1 & 0
		\end{pmatrix}
\end{IEEEeqnarray*}

In the binary basis of $\hat{e}_i$ and $\hat{e}_j$ the vertexes can be 
summarized as

\begin{IEEEeqnarray*}{rCl}
	V_0 & = & \lim_{\substack{\alpha \rightarrow 0\\ \beta \rightarrow \infty}}\exp\left(\alpha C_{ij} + \beta C_{ji}\right)\\
			& = & I + C_{ji} \notin St(\hat{\mathbbm{1}})\\
	V_1 & = & \lim_{\substack{\alpha \rightarrow \mathrm{i}\frac{\pi}{2}\\ \beta \rightarrow \mathrm{i}\frac{\pi}{2}}}\exp\left(\alpha C_{ij} + \beta C_{ji}\right)\\
			& = & I + C_{ij} + C_{ji} \in St(\hat{\mathbbm{1}})\\
	V_2 & = & \lim_{\substack{\alpha \rightarrow 0\\ \beta \rightarrow 0}}\exp\left(\alpha C_{ij} + \beta C_{ji}\right)\\
			& = & I \in St(\hat{\mathbbm{1}})\\
	V_3 & = & \lim_{\substack{\alpha \rightarrow \infty\\ \beta \rightarrow 0}}\exp\left(\alpha C_{ij} + \beta C_{ji}\right)\\
			& = & I + C_{ij} \notin St(\hat{\mathbbm{1}})
\end{IEEEeqnarray*}

% Need a figure showing the geometry of the limits

% What is the generalization of this limit process? How do we get higher dimensional vertexes?
% Need to show what a vertex is j any function n to n natural numbers consider V = I + sum Cij(i)

A general vertex $V$ of the convex polytope of stochastic $n \times n$ matrices 
in is given by 

\begin{IEEEeqnarray*}{rCl}
	V & = & I + \sum_{i=1}^n C_{ij\left(i\right)}
\end{IEEEeqnarray*}

where $j(i) : \left\lbrace 1,\dots,n \right\rbrace \mapsto J \subseteq \left\lbrace 1,\dots,n \right\rbrace$
is any one of the $n^n$ such functions. Given that the vertexes are linear 
combinations of $C_{ij}$, and it may seem plausible that the exponential of a 
linear combination of $C_{ij}$ is always linear combination of $C_{ij}$. In 
fact, this is true in general for any matrix Lie group $M$, namely it is the Lie 
algebra offset by the identity element $M = I + \mathfrak{m}$. This can be seen 
from the Taylor series expansion of the matrix exponential. It follows that for 
a $G = \sum_{ij} g_{ij} C_{ij} \in \mathfrak{st}(\hat{\mathbbm{1}})$ the matrix 
exponential is $\exp G = I + \sum_{ij} h_{ij} C_{ij}$.

Unfortunately, because polynomials of degree greater than four are generally 
unsolvable, the relationship between the coefficients $g_{ij}$ and $h_{ij}$ is 
highly non-trivial in most circumstances. An exception to this
difficulty can be found in the formulation of the of first exit
times from a fixed initial state. The generator of the first exit from $i$ to 
any state $j \ne i$ is given by $G_i = \sum_{i \ne j} \alpha_j C_{ij}$,
\footnote{A complete proof of the result will be given in chapter four.} 
from which we have

\begin{IEEEeqnarray*}{rCl}
	\exp G_i
		& = & I + \sum_{n=1}^{\infty} \frac{1}{n!} \left(-\sum_{i \ne j} \alpha_j\right)^{n-1} \sum_{i \ne j} \alpha_j C_{ij}\\
		& = & I +\frac{1 - e^{-\sum_{i \ne k} \alpha_k}}{\sum_{i \ne l} \alpha_l} \sum_{i \ne j} \alpha_j C_{ij}\\
		& = & I + \frac{1 - e^{-\sum_{i \ne k} \alpha_k}}{\sum_{i \ne l} \alpha_l} G_i
\end{IEEEeqnarray*}

Likewise the generator for the exclusive entrance to a state $j$, from any state 
$i \ne j$, is $G_j = \sum_{i \ne j} \alpha_i C_{ij}$, which yields

\begin{IEEEeqnarray*}{rCl}
	\exp G_j
		& = & I - \sum_{n=1}^{\infty} \frac{1}{n!} \sum_{i \ne j} \left(-\alpha_i\right)^n C_{ij}\\
		& = & I + \sum_{i \ne j} \left(1 - e^{-\alpha_i}\right) C_{ij}
\end{IEEEeqnarray*}

It should be clear now that $St(\hat{\mathbbm{1}})$ has a non-trivial structure;
most importantly it is connected, but not simply connected. This can be seen 
because $St(\hat{\mathbbm{1}})$ contains matrices with positive, negative, and 
complex determinants, while matrices with a determinant of zero are excluded, 
because they are not invertible. There is a simply connected normal sub-group of 
$St(\hat{\mathbbm{1}})$ that has particular importance to continuous time 
homogeneous Markov processes on finite state spaces.

% Need a figure and geometric interpretation of trying to shink a loop in the 
% complex plane to a point, when the loop is around a pole at the origin.

\begin{definition}
	The stochastic contraction Lie group $St^{+}(\hat{\mathbbm{1}})$ is the set
	of matrices such that $A \in St(\hat{\mathbbm{1}})$ and $\det A \in \mathbb{R}^{+}$
\end{definition}

Again this definition necessitates a proof of the claim in the previous 
paragraph.

\begin{corollary}
	$St^{+}(\hat{\mathbbm{1}})$ is a simply connected normal sub-group of $St(\hat{\mathbbm{1}})$
\end{corollary}

\begin{IEEEproof}
	It should be clear that $St^{+}(\hat{\mathbbm{1}})$ is a Lie sub-group of $St^{+}(\hat{\mathbbm{1}})$,
	thus we need only prove normality and simply connectedness.
	\begin{enumerate}
		\item Starting with normality, let $A \in St^{+}(\hat{\mathbbm{1}})$ and $B \in St(\hat{\mathbbm{1}})$,
		then
		\begin{IEEEeqnarray*}{rCl}
			\det \left( BAB^{-1} \right)
				& = & \left(\det B\right)\left(\det A\right)\left(\det B\right)^{-1}\\
				& = & \det A
		\end{IEEEeqnarray*}
		thus $BAB^{-1} \in St^{+}(\hat{\mathbbm{1}})$
		\item It is sufficient to prove that $St^{+}(\hat{\mathbbm{1}})$ is simply
		connected through the identity element.
		\item Starting with a continuous path $A\left(t\right) \in St^{+}(\hat{\mathbbm{1}})$
		parameterized by $t \in \left[0,1\right]$ such that $A\left(0\right) = A\left(1\right) = I$,
		by definition of the Lie algebra there exists a continuous path $G\left(t \right) = \sum_{ij} \alpha_{ij}\left(t\right) C_{ij} \in \mathfrak{st}(\hat{\mathbbm{1}})$ 
		such that $A\left(t\right) = \exp G\left(t\right)$, and $\alpha_{ij}\left(0\right) = \alpha_{ij}\left(1\right) = 0$.
		\item It follows that $\det A\left(t\right) = \exp\left(\sum_{ij} \alpha_{ij}\left(t\right)\right) \in \mathbb{R}^{+}$.
		\item Now consider $s \in \left[0,1\right]$, and $A_s\left(t\right) = \exp\left(sG\left(t\right)\right)$,
		then $A_1\left(t\right) = A\left(t\right)$ and $A_0\left(t\right) = I$,
		furthermore $\det A_s\left(t\right) = \exp\left(s \sum_{ij} \alpha_{ij}\left(t\right)\right) \in \mathbb{R}^{+}$.\hfill\IEEEQEDhere
	\end{enumerate}
\end{IEEEproof}

The use of the nomenclature of contraction is in deference to the equivalent
definition used for the generators of continuous Markov processes on finite 
state spaces. Of course every good Lie group deserves a Lie algebra.

\begin{definition}
	Let $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$ denote the stochastic contraction Lie 
	algebra of $St^{+}(\hat{\mathbbm{1}})$
\end{definition}

This definition admits a similar characterization as before.

\begin{corollary}
	$C_{ij}$ over $\mathbb{R}$ generates $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$.
\end{corollary}

\begin{IEEEproof}
	The result follows in much the same method as the central theorem of this 
	chapter, except to show that $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$ is a real
	vector space over the basis $C_{ij}$, whose main argument requires checking
	the condition of linear sum and scalar multiplication closure:
	\begin{enumerate}
		\item For any $\alpha_{ij} \in \mathbb{C}$ such that $\exp\left(\sum_{ij} \alpha_{ij} C_{ij}\right) \in St^{+}(\hat{\mathbbm{1}})$
		Jacobi's formula requires that $\mathbb{I}m\left(\sum_{ij} \alpha_{ij}\right) \equiv 0 \bmod 2 \pi$.
		\item It follows that for $\exp\left(\sum_{ij} \alpha_{ij} C_{ij}\right), \exp\left(\sum_{ij} \beta_{ij} C_{ij}\right) \in St^{+}(\hat{\mathbbm{1}})$
		we have
		\begin{IEEEeqnarray*}{rCl}
			0 
				& \equiv & \mathbb{I}m\left(\sum_{ij} \alpha_{ij}\right) + \mathbb{I}m\left(\sum_{ij} \beta_{ij}\right) \bmod 2 \pi \\
				& \equiv & \mathbb{I}m\left(\sum_{ij} \alpha_{ij} + \beta_{ij}\right) \bmod 2 \pi
		\end{IEEEeqnarray*}
		\item Thus $\exp\left(\sum_{ij} \left(\alpha_{ij} + \beta_{ij}\right) C_{ij}\right) \in St^{+}(\hat{\mathbbm{1}})$.
		\item Finally checking scalar multiplication, for fixed $a \in \mathbb{C}$,
		and any $\alpha_{ij} \in \mathbb{C}$ such that $\exp\left(\sum_{ij} \alpha_{ij} C_{ij}\right) \in St^{+}(\hat{\mathbbm{1}})$
		we have
		\begin{IEEEeqnarray*}{+rCl+x*}
			0 
				& \equiv & \mathbb{I}m\left(a \sum_{ij} \alpha_{ij}\right) \bmod 2 \pi \\
				& \equiv & \mathbb{R}e\left(a\right) \mathbb{I}m\left(\sum_{ij} \alpha_{ij}\right) + \mathbb{I}m\left(a\right) \mathbb{R}e\left(\sum_{ij} \alpha_{ij}\right) \bmod 2 \pi \\
				& \equiv & \mathbb{I}m\left(a\right) \mathbb{R}e\left(\sum_{ij} \alpha_{ij}\right) \bmod 2 \pi \\
				& = & \mathbb{I}m\left(a\right) & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

That $St^{+}(\hat{\mathbbm{1}})$ is a simply connected normal Lie sub-group has 
an important consequence for the generator estimation methods developed in the 
next chapter. The methods are all constrained to algebraic operations, so that
by closure of the Lie sub-algebra the algorithms will always result in 
generators from $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$. This can be seen because 
any continuous time homogeneous path through $St(\hat{\mathbbm{1}})$ defined 
must always start at the identity matrix. Thus if the basis $\hat{e}_i$ 
enumerates a finite state space, then the generator estimated by algebraic 
operations with respect to $C_{ij}$ will always have real (positive) expansion 
in the basis $C_{ij}$. This will occur even if a suitable complex generator is 
used to generate real (positive) transition probabilities. We can interpret this 
as meaning that $\mathfrak{st}^{+}(\hat{\mathbbm{1}})$ is a closed branch of the 
matrix logarithm. 

% The resolvent as either the Laplace or Fourier transform of an element of st(1)
% extends St(1) to Gl(1) through contours that intersect with st(1) at the element
% being transformed L[exp(ut)exp(tG)] = 1/(u+G) = u exp(-G'). Gl(1) is the Lie 
% group of of invertible matrices with 1 as the eigenvector. gl(1) = st(1) + 1 

We have developed an interpretation of the Eigen equation $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$
as a conservation of the row sums of $A$; likewise the Eigen equation $A^T \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$
can be interpreted as the conservation of the column sums of $A$. The dual 
definitions for the Lie group and algebra follow natural.

\begin{definition}
	Let $St^T(\hat{\mathbbm{1}})$ denote the dual stochastic Lie group of 
	invertible matrices whose transpose is stochastic with respect to $\hat{\mathbbm{1}}$.
\end{definition}

\begin{definition}
	Let $\mathfrak{st}^T(\hat{\mathbbm{1}})$ denote the dual stochastic Lie 
	algebra of $St^T(\hat{\mathbbm{1}})$.
\end{definition}

Thus if $C_{ij}$ are generators of $\mathfrak{st}(\hat{\mathbbm{1}})$ then $C_{ij}^T = \left(\hat{e}_j - \hat{e}_i \right) \otimes \hat{e}_i$
are generators of $\mathfrak{st}^T(\hat{\mathbbm{1}})$. The definitions of the
dual stochastic contraction Lie group $St^{+T}(\hat{\mathbbm{1}})$ and Lie algebra $\mathfrak{st}^{+T}(\hat{\mathbbm{1}})$
follow analogously. That $St(\hat{\mathbbm{1}}) \cap St^T(\hat{\mathbbm{1}})$ 
is a Lie group and $\mathfrak{st}(\hat{\mathbbm{1}}) \cap \mathfrak{st}^T(\hat{\mathbbm{1}})$ 
is a Lie algebra will be foundational for the next section.

\section{Doubly Stochastic Matrices}
Doubly stochastic matrices require row and column conservation of the vector $\hat{\mathbbm{1}}$, 
in the sense that both $A \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ and $A^T \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$ 
must hold. The group of invertible doubly stochastic matrices is then a subgroup
of the group of stochastic matrices. The two constraints of row and column 
conservation leaves only $\left(n - 1\right)^2$ linear degrees of freedom. This 
is an important clue in the construction of a canonical representation. In fact 
the representation can be found by choosing one additional vector $\hat{e}_n$, 
from the basis constructed in the previous section, to center the combinatorial 
construction of the generators of the algebra around. This vector plays a 
similar role to the diagonal in the previous construction and is used to balance 
the row and column sums back to zero. As in the previous section we start with 
a foundational definition.

\begin{definition}
	Let $St(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$ denote the doubly stochastic 
	Lie group of invertible matrices $A$ such that both $A$ and $A^T$ are 
	stochastic with respect to $\hat{\mathbbm{1}}$
\end{definition}

We can immediately observe with out proof that $St(\hat{\mathbbm{1}}, \hat{\mathbbm{1}}) = St(\hat{\mathbbm{1}}) \cap St^T(\hat{\mathbbm{1}})$;
leading to the next definition.

\begin{definition}
	Let $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$ denote the doubly 
	stochastic Lie algebra of $St(\hat{\mathbbm{1}},\hat{\mathbbm{1}})$.
\end{definition}

Again, it should be clear that $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}}) = \mathfrak{st}(\hat{\mathbbm{1}}) \cap \mathfrak{st}^T(\hat{\mathbbm{1}})$.
The implication being that $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$
is the algebra of all matrices $A$ such that $\hat{\mathbbm{1}}$ is in the 
kernel of both $A$ and $A^T$. As with $St(\hat{\mathbbm{1}})$, the Lie group $St(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$
is not connected, and contains the splitting contraction sub-group $St^{+}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$,
with its similarly defined contraction sub-algebra $\mathfrak{st}^{+}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$. 
$St^{+}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$ has the same properties of 
normality and simple connectedness within $St(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$; 
of course it is not normal within $St(\hat{\mathbbm{1}})$.

We can then find canonical generators of $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$
by similar methods as in the previous section. Given a constructed basis $\hat{e}_i$
such that $\left\langle \hat{e}_i, \hat{\mathbbm{1}} \right\rangle = \frac{1}{\sqrt{n}}$
we pick a single arbitrary element from the basis, say $\hat{e}_n$, the last
element for example. We then balance a transition rate from $i$ to $j$, with the
reverse rates from $j$ to $n$ and $n$ to $i$, yielding the matrix $C_{ijn} = C_{ij} + C_{ni} + C_{jn}$.

% Need a figure here of the circuit

The matrices $C_{ijn}$ are elements of $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$. 
Furthermore they are a closed set with respect to matrix transposition, because 
$C_{ijn}^T = C_{jin}$. The algebra $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$
is isomorphic to the space of $\left(n-1\right) \times \left(n-1\right)$ 
matrices, which can be seen by the relationship, for any $i,j \le n-1$.

\begin{IEEEeqnarray*}{rCl}
	C_{ijn} - C_{iin} - C_{jjn}
		& = & \hat{e}_i \otimes \hat{e_j} - \hat{e}_i \otimes \hat{e}_n - \hat{e}_n \otimes \hat{e}_j + \hat{e}_n \otimes \hat{e}_n
\end{IEEEeqnarray*}

The intuition being that any $n \times n$ matrix with fixed row and column sums
can be created by starting with any $\left(n-1\right) \times \left(n-1\right)$ 
matrix and appending a compensating $n$ row and $n$ column. This relationship is 
implicitly used extensively in proving the following lemma and corollary on the 
products, commutators, and structure constants of $C_{ijn}$.

\begin{lemma}
	\begin{IEEEeqnarray*}{rCl}
		C_{ijn}C_{kln} & = &
		\begin{cases}
			C_{jin} - 2C_{ijn} & i=k \text{ and } j=l,\\
			- \left(C_{ijn} + C_{jin}\right) & i=l \text{ and } j=k,\\
			C_{jin} - C_{jjn} - C_{iin} + C_{lln} - C_{iln} & i=k,\\
			C_{jkn} - C_{iin} - C_{jjn} - C_{kkn} & i=l,\\
			C_{iln} - C_{ijn} - C_{jln} & j=k,\\
			C_{jkn} - C_{ijn} + C_{iin} - C_{jjn} - C_{kkn} & j=l,\\
			C_{jkn} - C_{jjn} - C_{kkn} & \text{otherwise}.
		\end{cases}
	\end{IEEEeqnarray*}
\end{lemma}

\begin{IEEEproof}
	We proceed by calculating the terms of the products and then simplifying the 
	cases; assuming $i \neq j$, $k \neq l$, and $i,j,k,l \neq n$.
	\begin{enumerate}
		\item Term wise computation of the Kronecker products yields
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{kln}
				& = & \left(\hat{e}_i \otimes \hat{e}_j - \hat{e}_i \otimes \hat{e}_i + \hat{e}_n \otimes \hat{e}_i - \hat{e}_n \otimes \hat{e}_n + \hat{e}_j \otimes \hat{e}_n - \hat{e}_j \otimes \hat{e}_j\right)\\
				&   & \cdot \left(\hat{e}_k \otimes \hat{e}_l - \hat{e}_k \otimes \hat{e}_k + \hat{e}_n \otimes \hat{e}_k - \hat{e}_n \otimes \hat{e}_n + \hat{e}_l \otimes \hat{e}_n - \hat{e}_l \otimes \hat{e}_l\right)\\
				& = & - \hat{e}_n \otimes \hat{e}_k + \hat{e}_n \otimes \hat{e}_n + \hat{e}_j \otimes \hat{e}_k - \hat{e}_j \otimes \hat{e}_n\\
				&   & + \delta_{ik}\left(- \hat{e}_i \otimes \hat{e}_l + \hat{e}_i \otimes \hat{e}_k + \hat{e}_n \otimes \hat{e}_l - \hat{e}_n \otimes \hat{e}_k\right)\\
				&   & + \delta_{il}\left(- \hat{e}_i \otimes \hat{e}_n + \hat{e}_i \otimes \hat{e}_l + \hat{e}_n \otimes \hat{e}_n - \hat{e}_n \otimes \hat{e}_l\right)\\
				&   & + \delta_{jk}\left(\hat{e}_i \otimes \hat{e}_l - \hat{e}_i \otimes \hat{e}_k - \hat{e}_j \otimes \hat{e}_l + \hat{e}_j \otimes \hat{e}_k\right)\\
				&   & + \delta_{jl}\left(\hat{e}_i \otimes \hat{e}_n - \hat{e}_i \otimes \hat{e}_l - \hat{e}_j \otimes \hat{e}_n + \hat{e}_j \otimes \hat{e}_l\right)\\
				& = & C_{jkn} - C_{jjn} - C_{kkn} + \delta_{ik} \left(C_{lln} - C_{iln}\right) - \delta_{il} C_{iin}\\
				&   & + \delta_{jk} \left(C_{jjn} + C_{iln} - C_{ijn} - C_{jln}\right) + \delta_{jl} \left(C_{iin} - C_{ijn}\right)
		\end{IEEEeqnarray*}
		\item The cases follow from simplifying the $\delta$ functions; starting
		with $i=k$ and $j=l$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{ijn}
				& = & C_{jin} - C_{jjn} - C_{iin} + C_{jjn} - C_{ijn} + C_{iin} - C_{ijn}\\
				& = & C_{jin} - 2C_{ijn}
		\end{IEEEeqnarray*}
		\item When $i=l$ and $j=k$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{jin}
				& = & C_{jjn} - C_{jjn} - C_{jjn} + C_{jjn} + C_{iin} - C_{ijn} - C_{jin} - C_{iin}\\
				& = & - \left(C_{ijn} + C_{jin}\right)
		\end{IEEEeqnarray*}
		\item When $i=k$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{iln}
				& = & C_{jin} - C_{jjn} - C_{iin} + C_{lln} - C_{iln}
		\end{IEEEeqnarray*}
		\item When $i=l$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{kin}
				& = & C_{jkn} - C_{iin} - C_{jjn} - C_{kkn}
		\end{IEEEeqnarray*}
		\item When $j=k$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{jln}
				& = & C_{jjn} - C_{jjn} - C_{jjn} + C_{jjn} + C_{iln} - C_{ijn} - C_{jln}\\
				& = & C_{iln} - C_{ijn} - C_{jln}
		\end{IEEEeqnarray*}
		\item When $j=l$
		\begin{IEEEeqnarray*}{rCl}
			C_{ijn}C_{kjn}
				& = & C_{jkn} - C_{ijn} + C_{iin} - C_{jjn} - C_{kkn}
		\end{IEEEeqnarray*}
		\item When none of the conditions apply
		\begin{IEEEeqnarray*}{+rCl+x*}
			C_{ijn}C_{kln}
				& = & C_{jkn} - C_{jjn} - C_{kkn} & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

Moving immediately to the commutators we have
% the following needs major fixing for j=k
\begin{corollary}
	\begin{IEEEeqnarray*}{rCl}
		\left[C_{ijn},C_{kln}\right] & = &
		\begin{cases}
			0 & i=k \text{ and } j=l,\\
			0 & i=l \text{ and } j=k,\\
			C_{ijn} + C_{jin} - C_{il} - C_{lin} - 2C_{jjn}  + 2C_{lln} & i=k,\\
			C_{ijn} + C_{jkn} - C_{kjn} + C_{kin} - C_{iin} - C_{jjn} - C_{kkn} & i=l,\\
			C_{iln} - C_{lin} - C_{ijn} - C_{jln} - C_{iin} - C_{jjn} - C_{lln} & j=k,\\
			C_{iln} - C_{lin} - C_{ijn} - C_{jln} + C_{iin} + C_{jjn} + C_{lln} & j=l,\\
			C_{jkn} - C_{jjn} - C_{kkn} - C_{lin} + C_{lln} + C_{iin} & \text{otherwise}.
		\end{cases}
	\end{IEEEeqnarray*}
\end{corollary}

\begin{IEEEproof}
	We work case wise through the equalities; assuming $i \neq j$, $k \neq l$, and 
	$i,j,k,l \neq n$.
	\begin{enumerate}
		\item Starting with $i=k$ and $j=l$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{ijn}\right]
				& = & C_{ijn}C_{ijn} - C_{ijn}C_{ijn}\\
				& = & 0
		\end{IEEEeqnarray*}
		\item When $i=l$ and $j=k$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{jin}\right]
				& = & C_{ijn}C_{jin} - C_{jin}C_{ijn}\\
				& = & - \left(C_{ijn} + C_{jin}\right) + \left(C_{jin} + C_{ijn}\right)\\
				& = & 0
		\end{IEEEeqnarray*}
		\item When $i=k$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{iln}\right]
				& = & C_{ijn}C_{iln} - C_{iln}C_{ijn}\\
				& = & \left(C_{jin} - C_{jjn} - C_{iin} + C_{lln} - C_{iln}\right)\\
				&   & - \left(C_{lin} - C_{lln} - C_{iin} + C_{jjn} - C_{ijn}\right)\\
				& = & C_{ijn} + C_{jin} - C_{il} - C_{lin} - 2C_{jjn}  + 2C_{lln}
		\end{IEEEeqnarray*}
		\item When $i=l$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{kin}\right]
				& = & C_{ijn}C_{kin} - C_{kin}C_{ijn}\\
				& = & \left(C_{jkn} - C_{iin} - C_{jjn} - C_{kkn}\right) - \left(C_{kjn} - C_{kin} - C_{ijn}\right)\\
				& = & C_{ijn} + C_{jkn} - C_{kjn} + C_{kin} - C_{iin} - C_{jjn} - C_{kkn}
		\end{IEEEeqnarray*}
		\item When $j=k$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{jln}\right]
				& = & C_{ijn}C_{jln} - C_{jln}C_{ijn}\\
				& = & \left(C_{iln} - C_{ijn} - C_{jln}\right) - \left(C_{lin} - C_{jjn} - C_{lln} - C_{iin}\right)\\
				& = & C_{iln} - C_{lin} - C_{ijn} - C_{jln} + C_{iin} + C_{jjn} + C_{lln}
		\end{IEEEeqnarray*}
		\item When $j=l$
		\begin{IEEEeqnarray*}{rCl}
			\left[C_{ijn},C_{kjn}\right]
				& = & C_{ijn}C_{kjn} - C_{kjn}C_{ijn}\\
				& = & \left(C_{jkn} - C_{ijn} + C_{iin} - C_{jjn} - C_{kkn}\right)\\
				&   & - \left(C_{jin} - C_{kjn} + C_{kkn} - C_{jjn} - C_{iin}\right)\\
				& = & C_{jkn} + C_{kjn} - C_{ijn} - C_{jin} + 2C_{iin} - 2C_{kkn}
		\end{IEEEeqnarray*}
		\item When none of the conditions apply
		\begin{IEEEeqnarray*}{+rCl+x*}
			\left[C_{ijn},C_{kln}\right]
				& = & C_{ijn}C_{kln} - C_{kln}C_{ijn}\\
				& = & C_{jkn} - C_{jjn} - C_{kkn} - C_{lin} + C_{lln} + C_{iin} & \IEEEQEDhere
		\end{IEEEeqnarray*}
	\end{enumerate}
\end{IEEEproof}

Restricting to the matrices where both the row and column sums are zero, which
is equivalent to demanding the conservation of the transition rates, or 
infinitesimal flows of probability, introduces a significant degree of
complexity to the algebra. In particular demanding that all the transition rates
be balanced by transitions through $\hat{e}_n$ means that only the simplest two
and three state processes have easily calculable algebras. Nevertheless, the 
result makes the sibling theorem accessible.

\begin{theorem}
	$C_{ijn}$ are canonical generators of $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$.
\end{theorem}

\begin{IEEEproof}
	The proof proceeds in the same manner as the proof of the sibling theorem in
	the previous section.
	\begin{enumerate}
		\item As discussed before $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$
		is an $\left(n-1\right)^2$ dimensional vector space.
		\item By construction there are only $\left(n-1\right)^2$ matrices $C_{ijn}$
		for a fixed choice of $\hat{e}_n$.
		\item Through induction the matrices $C_{ijn}$ are linearly independent for
		a fixed choice of $\hat{e}_n$.
		\item Thus the matrices $C_{ijn}$, for a fixed choice of $\hat{e}_n$, are a 
		basis for $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$.
		\item By the previous lemma the commutators of matrices $C_{ijn}$ are linear
		combinations of themselves.
		\item It follows then that the smallest algebra that contains the matrices $C_{ijn}$
		is $\mathfrak{st}(\hat{\mathbbm{1}}, \hat{\mathbbm{1}})$.\hfill\IEEEQEDhere
	\end{enumerate}
\end{IEEEproof}

As with the stochastic Lie algebra the generators of the doubly stochastic Lie 
algebra are not unique, not only do they depend on the choice of the basis $\hat{e}_i$ 
but also on the choice of the basis element $\hat{e}_n$ used to sum the rows and 
columns to zero.

% Unlike stochastic Lie group there are no nice guareentees on properness with
% respect to postive sums. No matter what generators of the algebra are chosen
% there will always be Markov processes that require negative terms in the sum.
% the physical intuition is that to composing cicuits will require cancellation.

% Discuss Birkhoff polytope versus Lie group, construct vertexes vis-a-vi 
% Birkhoff-von Neumann theorem. Again vector space structure means every
% DS is linear sum.

% Basis choice unqiuely gives the Birkhoff polytope, it is independent of the
% choice of balancing unit vector. Requires proof the vertexes are 
% independent of balancing vector.