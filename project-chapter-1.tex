\chapter{Introduction}
\section{Motivation}
Markov processes are a central subject of study in probability theory, and are a 
rich source of distributions for parameter estimation in statistics\cite{billingsley_probability_1995,rogers_diffusions_2000,rogers_diffusions_2000-1}.
They have applications in diverse disciplines ranging through the physical and 
life sciences, including operations research, chemical process engineering, 
queuing theory, communications theory, natural language processing, finance, and 
machine learning. Under mild assumptions and constraints they offer tractable,
and even closed form models; that can be reasoned about using physical heuristic 
analogies, and intuitive phenomenological interpretations. To varying degrees of 
rigor, methods for both simulation, and parameter estimation have been developed 
for many types of observed random and pseudo-random processes such as the syntax 
of sentences, disease states, cancer survival, epidemiology, and demographics. 
To apply Markov process a number of simplifying assumptions are made, including discretization of time and state spaces, 
homogeneity of the process, and restrictions of the allowed transitions. The simplifications have
resulted in models such as phase type distributions, branching processes, 
birth-death processes, and hidden Markov models.

State of the art computational methods are focused on maximum likelihood 
parameter estimation by expectation maximization of hidden Markov Models; which 
assumes a finite state space obscured by random noise, with discrete homogeneous 
time steps, and all times of transitions being observed. The discretization of 
time allows for the time evolution of transition probabilities to be explicitly 
parameterized through matrix multiplication. The discrete time construction of
hidden Markov models is successfully exploited by the Baum-Welch, Viterbi, and 
forward-backward algorithms to estimate parameters.

In contrast continuous time homogeneous Markov processes on a finite state space
are more naturally parameterized through the generator, because the time evolution is 
represented through matrix exponentiation. Unfortunately parameterization of the 
generators of Markov processes, in more than four states, does not in general 
yield tractable closed from transition probabilities. This is because any 
explicit formulation of the transition probabilities from the generator would 
require solving the characteristic polynomial of the generator, which is not 
generally possible in dimensions greater than four. Yet computational 
approximations of the matrix exponential have been well developed, with methods 
to compute the gradient receiving recent attention. The focus of this recent research has 
been on computing the condition number of numerical problems, as a measure of 
convergence and stability of the numerical solutions\cite{al-mohy_computing_2009}.

Given a computational method to calculate the matrix exponential, and it's 
gradient, and Hessian, an application of the chain rule then allows for the 
computation of maximum likelihood estimates of any differentiable
parameterization of the generators of a continuous time homogeneous Markov 
process on a finite state space. Of particular interest in such a method are stopped statistics, like the first hitting 
times of transitions from a fixed source state to a fixed target state. As such 
this work extends the current computational methods to include the Hessian of the 
matrix exponential; and further develops an alternate direct computation of the 
gradient of the matrix exponential.

Throughout this work we will attempt to conform to a simplified version of 
Lamport's guide to structuring, and presenting proofs\cite{lamport_how_2012}.

\section{Overview}
From the perspective of Lie theory, classical parameter estimation of Markov 
processes has been a manifold first approach; starting with an explicit 
construction of an extrinsic smooth coordinate chart (parameterization) on a 
neighborhood of the sub-manifold to which the generators belong, and only then 
looking for computational simplifications and solutions. As hinted to in the 
previous section, we will proceed with an algebra first approach; developing the 
intrinsic algebraic structure of the generators of the Lie algebra, and then 
exploiting the implicit function theorem to carry out computations in specific 
parameterizations.

The second chapter establishes the algebraic and analytic closure properties
necessary for chapter three. Chapter two has a secondary role to help develop the 
physical intuition for the stochastic Lie group necessary to work through the 
derivatives and approximations of chapter three.

The third chapter derives the the first and second order derivatives of the exponential
map and their Pad\'{e} Approximation.

The fourth chapter derives the maximum likelihood estimators from first hitting times, and the Newton-Raphson computation.

The fifth chapter concludes with summarizing remarks and a discussion of the direction
for further investigation.