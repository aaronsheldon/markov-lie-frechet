\chapter{Introduction}
\section{Motivation}
Markov processes are a central subject of study in probability theory, and are a rich source
of distributions for parameter estimation in statistics\cite{billingsley_probability_1995,rogers_diffusions_2000,rogers_diffusions_2000-1}.
They have applications in diverse disciplines ranging through the physical and life
sciences, including operations research, chemical process engineering, queuing theory,
communications theory, natural language processing, finance, and machine learning. Under
mild assumptions and constraints Markov processes offer tractable, and even closed form 
models; that can be reasoned about using physical heuristic analogies, and intuitive
phenomenological interpretations. To varying degrees of rigor, methods for both simulation,
and parameter estimation have been developed for many types of observed random and
pseudo-random processes such as the syntax of sentences, disease states, cancer survival,
epidemiology, and demographics. To apply Markov process a number of simplifying assumptions
are made, including discretization of time and state spaces, homogeneity of the process, and
restrictions of the allowed transitions. The simplifications have resulted in models such as
phase type distributions, branching processes, birth-death processes, and hidden Markov
models.

State of the art computational methods are focused on maximum likelihood parameter
estimation by expectation maximization of hidden Markov Models; which assumes a finite state
space obscured by random noise, with discrete homogeneous time steps, and all times of
transitions being observed. The discretization of time allows for the time evolution of
transition probabilities to be explicitly parameterized through matrix multiplication. The
discrete time construction of hidden Markov models is successfully exploited by the
Baum-Welch, Viterbi, and forward-backward algorithms to estimate parameters.

In contrast continuous time homogeneous Markov processes on a finite state space are more
naturally parameterized through the generator, because the time evolution is represented
through matrix exponentiation. Unfortunately parameterization of the generators of Markov
processes, in more than four states, does not, in general, yield tractable closed from
transition probabilities. This is because any explicit formulation of the transition
probabilities from the generator would require solving the characteristic polynomial of the
generator, which is not generally possible in dimensions greater than four. Yet
computational approximations of the matrix exponential have been well developed, with
methods to compute the gradient receiving recent attention. The focus of this recent
research has been on computing the condition number of numerical problems, as a measure of 
convergence, and stability of the numerical solutions\cite{al-mohy_computing_2009}.

Given a computational method to calculate the matrix exponential, it's gradient, and
Hessian, an application of the chain rule then allows for the computation of maximum
likelihood estimates of any differentiable parameterization of the generators of a
continuous time homogeneous Markov process on a finite state space. Of particular interest
in such a method are stopped statistics, like the first hitting times of transitions from a
fixed source state to a fixed target state. As such this work extends the current
computational methods to include the Hessian of the matrix exponential; and further develops
an alternate direct computation of the gradient of the matrix exponential.

Throughout this work we will attempt to conform to a simplified version of Lamport's guide
to structuring, and presenting proofs\cite{lamport_how_2012}.
\section{Overview}
The Chapman-Kolmogorov equation asserts that every Markov transition probability can be 
represented by a suitable choice of invertible bounded linear operator, that has at least
one Eigen vector with a unit Eigen value. Conversely any choice of invertible bounded linear 
operator, with at least one Eigen vector with a unit Eigen value, can generate a Markov 
transition probability. This characterization of Markov transition probabilities through an
equivalence with invertible bounded linear operators is so intrinsic to Markov processes
that it nearly serves as the definition of a Markov process \cite{rogers_diffusions_2000}.
For a particular Markov process these transitions will form a path through a semi-group.
This semi-group always resides within a Lie group, and thus the generators of the semi-group
reside in the associated Lie algebra. In contrast to the usual analysis of Markov transition
probabilities using resolvents, in the Lie theoretic approach the most general formulation
begins with a closed connected path $G_t$ through a Lie algebra on a space of bounded linear
operators. The Markov transition probabilities the arise from the exponential map of the Lie
algebra to the Lie group. 
\footnote{Usually the linear operators are over some form of $\mathscr{L}^1 \bigcap \mathscr{L}^2$ space of distributions}
\begin{IEEEeqnarray*}{rCl}
	\mathbb{E}\left[X_{t+\Delta t} = \vec{u} \left\| X_{t}=\vec{v} \right.\right]
		& = & \left\langle \vec{u}, \exp\left(\int_t^{t+\Delta t} G_s ds \right) \vec{v} \right\rangle
\end{IEEEeqnarray*}
Knowledge of the stochastic Lie group and algebra provides concrete, and exploitable 
guarantees on the analytic and algebraic properties of the semi-group. For example the
following matrix parameterization
\begin{IEEEeqnarray*}{rCl}
	M_s
		& = & \begin{bmatrix}
			e^{-t} & 1 - e^{-t} \\
			1 - e^{-t} & e^{-t}
		\end{bmatrix}
\end{IEEEeqnarray*}
is a valid stochastic matrix, as $M_t \hat{\mathbbm{1}} = \hat{\mathbbm{1}}$
for all $t \ge 1$. But it is not a Markov process because at $t = \ln 2$ the $\det M_t = 0$,
so that the dual vector $\left[-1,1\right]$ representing the parity statistic on a two state
process vanishes
\begin{IEEEeqnarray*}{rCl}
	\left[-1,1\right] M_t
		& = & \left[-1,1\right]
			\begin{bmatrix}
				e^{-t} & 1 - e^{-t} \\
				1 - e^{-t} & e^{-t}
			\end{bmatrix}\\
		& = & 0
\end{IEEEeqnarray*}
In the context of Lie theory, the path $t$ is neither connected nor closed in the Lie
algebra.

From the perspective of Lie theory, classical parameter estimation of Markov processes has
been a manifold first approach; starting with an explicit construction of an extrinsic
smooth coordinate chart (parameterization) on a neighborhood of the sub-manifold to which
the generators belong, and only then looking for computational simplifications and
solutions. As hinted to in the previous section, we will proceed with an algebra first
approach; developing the intrinsic algebraic structure of the generators of the Lie algebra,
and then exploiting the chain rule to carry out computations in specific parameterizations.

The second chapter establishes the algebraic and analytic closure properties necessary for 
chapter three, and establishes the notation used throughout all the following chapters.
Chapter two has a secondary role in helping to develop the physical intuition for the 
stochastic Lie group needed to work through the derivatives and approximations of chapter 
three. However, the work on computing the logarithms of permutations can be set aside, as 
the material was developed to gain a fuller understanding of the structure of the stochastic 
Lie algebra; and to highlight, through the explicit construction of examples, the
non-trivial degeneracy of the branches of the matrix logarithm.

The third chapter reviews the definition for the gradient of exponential map, and continues
on to derive a Pad\'{e} approximation of the gradient of the exponential map. An analytic
form for the Hessian of the exponential map is then developed, followed by an algorithm that
to calculate the Hessian of the exponential map. The Hessian approximation algorithm
involves a combination of a Pad\'{e} approximation of a linear term, and a novel recursive 
calculation of a bilinear non-commutative perturbation to the Hessian.

The fourth chapter seeks to illustrate the material developed in the preceding two chapters.
First the cumulative distribution of the stopped statistic of first hitting times is recast 
in the stochastic Lie algebra developed in chapter two. These results are then put to use in
developing a model for an aging process; which is a finite state reversible birth-death
process. The chapter concludes by laying out the algorithms to calculate the gradient and
Hessian of the log-likelihood of the aging process, and hence a Newton-Raphson method for
maximization.

Finally, the fifth chapter concludes with summarizing remarks, and a discussion of the
direction for further investigation.