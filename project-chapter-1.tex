\chapter{Introduction}
\section{Motivation}
Markov processes are a central subject of study in probability theory, and are a rich source
of distributions for parameter estimation in statistics\cite{billingsley_probability_1995,rogers_diffusions_2000,rogers_diffusions_2000-1}.
They have applications in diverse disciplines ranging through the physical and life
sciences, including operations research, chemical process engineering, queuing theory,
communications theory, natural language processing, finance, and machine learning. Under
mild assumptions and constraints they offer tractable, and even closed form models; that can
be reasoned about using physical heuristic analogies, and intuitive phenomenological
interpretations. To varying degrees of rigor, methods for both simulation, and parameter
estimation have been developed for many types of observed random and pseudo-random processes
such as the syntax of sentences, disease states, cancer survival, epidemiology, and
demographics. To apply Markov process a number of simplifying assumptions are made,
including discretization of time and state spaces, homogeneity of the process, and
restrictions of the allowed transitions. The simplifications have resulted in models such as
phase type distributions, branching processes, birth-death processes, and hidden Markov
models.

State of the art computational methods are focused on maximum likelihood parameter
estimation by expectation maximization of hidden Markov Models; which assumes a finite state
space obscured by random noise, with discrete homogeneous time steps, and all times of
transitions being observed. The discretization of time allows for the time evolution of
transition probabilities to be explicitly parameterized through matrix multiplication. The
discrete time construction of hidden Markov models is successfully exploited by the
Baum-Welch, Viterbi, and forward-backward algorithms to estimate parameters.

In contrast continuous time homogeneous Markov processes on a finite state space are more
naturally parameterized through the generator, because the time evolution is represented
through matrix exponentiation. Unfortunately parameterization of the generators of Markov
processes, in more than four states, does not in general yield tractable closed from
transition probabilities. This is because any explicit formulation of the transition
probabilities from the generator would require solving the characteristic polynomial of the
generator, which is not generally possible in dimensions greater than four. Yet
computational approximations of the matrix exponential have been well developed, with
methods to compute the gradient receiving recent attention. The focus of this recent
research has been on computing the condition number of numerical problems, as a measure of 
convergence and stability of the numerical solutions\cite{al-mohy_computing_2009}.

Given a computational method to calculate the matrix exponential, and it's gradient, and
Hessian, an application of the chain rule then allows for the computation of maximum
likelihood estimates of any differentiable parameterization of the generators of a
continuous time homogeneous Markov process on a finite state space. Of particular interest
in such a method are stopped statistics, like the first hitting times of transitions from a
fixed source state to a fixed target state. As such this work extends the current
computational methods to include the Hessian of the matrix exponential; and further develops
an alternate direct computation of the gradient of the matrix exponential.

Throughout this work we will attempt to conform to a simplified version of Lamport's guide
to structuring, and presenting proofs\cite{lamport_how_2012}.
\section{Overview}
The Chapman-Kolmogorov equation asserts that every Markov transition can be represented by 
a suitable choice of invertible bounded linear operator with at least one Eigen vector with 
a unit Eigen value; and conversely any choice of invertible bounded linear operator with at
least one Eigen vector with a unit Eigen value generates a Markov transition \cite{rogers_diffusions_2000}.
The for a particular Markov process these transitions will form a path through a semi-group.
This semi-group always resides within a Lie group, and thus the generators of the semi-group
reside in the associated Lie algebra. This knowledge provides concrete, and exploitable 
guarantees on the analytic and algebraic properties of the semi-group.

From the perspective of Lie theory, classical parameter estimation of Markov processes has
been a manifold first approach; starting with an explicit construction of an extrinsic
smooth coordinate chart (parameterization) on a neighborhood of the sub-manifold to which
the generators belong, and only then looking for computational simplifications and
solutions. As hinted to in the previous section, we will proceed with an algebra first
approach; developing the intrinsic algebraic structure of the generators of the Lie algebra,
and then exploiting the chain rule to carry out computations in specific parameterizations.

The second chapter establishes the algebraic and analytic closure properties necessary for 
chapter three, and establishes notation used throughout all the following chapters. Chapter
two has a secondary role to help develop the physical intuition for the stochastic Lie group
needed to work through the derivatives and approximations of chapter three. However the work
on computing the logarithms of permutations can be set aside, as the material was developed
to gain a fuller understanding of the structure of the stochastic Lie algebra.

The third chapter reviews the definition for the gradient of exponential map, and  continues
on to derives an analytic form for the Hessian of the exponential map. A Pad\'{e}
approximation of the gradient of the exponential map is then developed, followed by an
algorithm that to calculate the Hessian of the exponential map. The Hessian algorithm 
combines the Pad\'{e} approximation of the gradient with a novel recursive calculation of a
bilinear non-commutative perturbation to the Hessian.

The fourth chapter seeks to illustrate the material developed in the preceding two chapters.
First the cumulative distribution of the stopped statistic of first hitting times is recast 
in the stochastic Lie algebra developed in chapter two. These results are then put to use in
developing a model for an aging process; which is a finite state reversible birth-death
process. The chapter concludes by laying out the algorithms to calculate the gradient and
Hessian of the log-likelihood of the aging process, and hence a Newton-Raphson method for
maximization.

Finally, the fifth chapter concludes with summarizing remarks and a discussion of the
direction for further investigation.